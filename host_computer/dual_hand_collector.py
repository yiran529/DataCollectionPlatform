#!/usr/bin/env python3
"""
åŒæ‰‹åŒæ­¥æ•°æ®æ”¶é›†å™¨

åŒæ—¶æ”¶é›†å·¦å³æ‰‹çš„æ•°æ®ï¼š
- å·¦æ‰‹ï¼šå•ç›®ç›¸æœº + åŒç›®ç›¸æœº + è§’åº¦ç¼–ç å™¨
- å³æ‰‹ï¼šå•ç›®ç›¸æœº + åŒç›®ç›¸æœº + è§’åº¦ç¼–ç å™¨

æ‰€æœ‰æ•°æ®ä¿è¯æ—¶é—´åŒæ­¥å¯¹é½
"""

import sys
import os
import cv2
import numpy as np
import time
import threading
import yaml
import json
import glob
from dataclasses import dataclass
from typing import Optional, List, Dict
from collections import deque

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥sync_data_collector
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from data_coll.sync_data_collector import CameraReader, EncoderReader, SensorFrame

try:
    import minimalmodbus
except ImportError:
    minimalmodbus = None

try:
    import h5py
    HAS_H5PY = True
except ImportError:
    HAS_H5PY = False

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False


@dataclass
class HandFrame:
    """å•æ‰‹çš„åŒæ­¥å¸§"""
    stereo: np.ndarray
    mono: np.ndarray
    angle: float
    timestamp: float
    stereo_ts: float
    mono_ts: float
    encoder_ts: float
    idx: int


@dataclass
class DualHandFrame:
    """åŒæ‰‹åŒæ­¥å¸§"""
    left: HandFrame
    right: HandFrame
    timestamp: float
    idx: int


class HandCollector:
    """å•æ‰‹æ•°æ®æ”¶é›†å™¨ï¼ˆå¤ç”¨å•æ‰‹çš„åŒæ­¥é€»è¾‘ï¼‰"""
    
    def __init__(self, config: dict, hand_name: str):
        self.config = config
        self.hand_name = hand_name
        
        self.stereo: Optional[CameraReader] = None
        self.mono: Optional[CameraReader] = None
        self.encoder: Optional[EncoderReader] = None
        
        self._ready = False
        self._running = False
        self._recording = False
        
        # åŒæ­¥åç§»é‡
        self.stereo_mono_offset_ms = 0.0
        self.stereo_encoder_offset_ms = 0.0
        
        # ç«‹ä½“æ ¡æ­£å‚æ•°
        self.stereo_rectify_enabled = False
        self.stereo_map1_l = None
        self.stereo_map2_l = None
        self.stereo_map1_r = None
        self.stereo_map2_r = None
        self.stereo_calibration = None
        
        # å½•åˆ¶æ•°æ®ï¼ˆä½¿ç”¨dequeé™åˆ¶å¤§å°ï¼Œè‡ªåŠ¨ä¸¢å¼ƒæ—§æ•°æ®ï¼‰
        # æœ€å¤§å½•åˆ¶å¸§æ•°ï¼šé»˜è®¤1800å¸§ï¼ˆ30fps*60ç§’ï¼‰
        max_frames = config.get('max_record_frames', 1800)
        self._max_record_frames = max_frames
        self._record_start_ts = 0
        self._recorded_stereo: deque = deque(maxlen=max_frames)
        self._recorded_mono: deque = deque(maxlen=max_frames)
        self._recorded_encoder: deque = deque(maxlen=max_frames)
        self._record_lock = threading.Lock()
        self._record_thread = None
        self._record_stats = {'frames': 0, 'last_print': 0}
        
        # å¢é‡å¤åˆ¶ï¼šè®°å½•ä¸Šæ¬¡å¤„ç†çš„ç´¢å¼•
        self._last_copied_idx = {'stereo': 0, 'mono': 0, 'encoder': 0}
        
        # JPEGå‹ç¼©è´¨é‡
        self._jpeg_quality = config.get('jpeg_quality', 85)
    
    @property
    def is_ready(self) -> bool:
        return self._ready
    
    @property
    def is_recording(self) -> bool:
        return self._recording
    
    def start(self) -> bool:
        """å¯åŠ¨æ”¶é›†å™¨"""
        if self._running:
            return True
        
        self._running = True
        self._ready = False
        
        thread = threading.Thread(target=self._startup_routine, daemon=True)
        thread.start()
        return True
    
    def wait_ready(self, timeout: float = 30.0) -> bool:
        """ç­‰å¾…å°±ç»ª"""
        start = time.time()
        while not self._ready and (time.time() - start) < timeout:
            time.sleep(0.1)
        return self._ready
    
    def _startup_routine(self):
        """å¯åŠ¨æµç¨‹"""
        cfg = self.config
        
        print(f"\n[{self.hand_name}] åˆå§‹åŒ–...")
        
        # åˆå§‹åŒ–ç›¸æœº
        mono_cfg = cfg.get('mono', {})
        stereo_cfg = cfg.get('stereo', {})
        
        # åˆ›å»ºç›¸æœºå¯¹è±¡ï¼ˆä½†å…ˆä¸æ‰“å¼€ï¼‰
        self.stereo = CameraReader(
            stereo_cfg.get('device', 2),
            stereo_cfg.get('width', 3840),
            stereo_cfg.get('height', 1080),
            stereo_cfg.get('fps', 30),
            f"{self.hand_name}_STEREO"
        )
        
        self.mono = CameraReader(
            mono_cfg.get('device', 0),
            mono_cfg.get('width', 1280),
            mono_cfg.get('height', 1024),
            mono_cfg.get('fps', 30),
            f"{self.hand_name}_MONO"
        )
        
        # é‡è¦ï¼šå…ˆæ‰“å¼€ Stereo æ‘„åƒå¤´ï¼Œå†æ‰“å¼€ Mono
        # è¿™æ ·å¯ä»¥é¿å… USB ç«äº‰æ¡ä»¶å¯¼è‡´çš„é¢„çƒ­è¶…æ—¶
        print(f"[{self.hand_name}] æ‰“å¼€ Stereo æ‘„åƒå¤´...")
        if not self.stereo.open():
            print(f"[{self.hand_name}] âŒ Stereo æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥")
            self._running = False
            return
        
        print(f"[{self.hand_name}] æ‰“å¼€ Mono æ‘„åƒå¤´...")
        if not self.mono.open():
            print(f"[{self.hand_name}] âŒ Mono æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥")
            self.stereo.cap.release()  # é‡Šæ”¾ Stereo
            self._running = False
            return
        
        # åŠ è½½ç«‹ä½“æ ¡æ­£å‚æ•°
        self._load_stereo_rectification()
        
        # åˆå§‹åŒ–ç¼–ç å™¨
        encoder_cfg = cfg.get('encoder', {})
        port = encoder_cfg.get('port', '/dev/ttyUSB0')
        baudrate = encoder_cfg.get('baudrate', 115200)
        
        # ä»YAMLé…ç½®è¯»å–æ ¡å‡†å‚æ•°ï¼ˆä¼˜å…ˆï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•ä»æ–‡ä»¶è¯»å–
        calibration_cfg = encoder_cfg.get('calibration', {})
        calib_file = encoder_cfg.get('calibration_file', '')
        
        # æ£€æŸ¥ä¸²å£æ˜¯å¦å­˜åœ¨
        ports = sorted(glob.glob('/dev/ttyUSB*'))
        available_ports = ports + sorted(glob.glob('/dev/ttyACM*'))
        
        print(f"[{self.hand_name}] æ£€æŸ¥ç¼–ç å™¨ä¸²å£: {port}")
        print(f"[{self.hand_name}] å¯ç”¨ä¸²å£: {available_ports}")
        
        if port not in available_ports:
            if available_ports:
                print(f"[{self.hand_name}] âš ï¸ é…ç½®çš„ä¸²å£ {port} ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ {available_ports[0]}")
                port = available_ports[0]
            else:
                print(f"[{self.hand_name}] âš ï¸ æœªæ‰¾åˆ°å¯ç”¨ä¸²å£ï¼Œè·³è¿‡ç¼–ç å™¨åˆå§‹åŒ–")
                port = None
        
        if port:
            # æ£€æŸ¥ä¸²å£æƒé™
            if not os.access(port, os.R_OK | os.W_OK):
                print(f"[{self.hand_name}] âš ï¸ ä¸²å£ {port} æƒé™ä¸è¶³ï¼Œå°è¯•ä½¿ç”¨sudoæˆ–æ·»åŠ ç”¨æˆ·åˆ°dialoutç»„")
            
            # åˆ›å»ºEncoderReaderï¼ˆä½¿ç”¨ç©ºå­—ç¬¦ä¸²ä½œä¸ºcalibration_fileï¼Œå› ä¸ºæˆ‘ä»¬å°†æ‰‹åŠ¨è®¾ç½®ï¼‰
            self.encoder = EncoderReader(port, baudrate, '')
            
            # å¦‚æœYAMLä¸­æœ‰æ ¡å‡†é…ç½®ï¼Œç›´æ¥è®¾ç½®
            if calibration_cfg:
                self.encoder.angle_zero = calibration_cfg.get('angle_zero', 0.0)
                self.encoder.calibrated = calibration_cfg.get('calibrated', False)
                print(f"[{self.hand_name}] ç¼–ç å™¨æ ¡å‡†å‚æ•°: angle_zero={self.encoder.angle_zero:.2f}Â°, calibrated={self.encoder.calibrated}")
            # å¦åˆ™å°è¯•ä»æ–‡ä»¶åŠ è½½
            elif calib_file:
                # è§£ææ ¡å‡†æ–‡ä»¶è·¯å¾„
                if not os.path.isabs(calib_file):
                    # ç›¸å¯¹äºé…ç½®æ–‡ä»¶ç›®å½•
                    config_dir = os.path.dirname(os.path.abspath(__file__))
                    calib_file = os.path.join(config_dir, calib_file)
                if os.path.exists(calib_file):
                    self.encoder.calibration_file = calib_file
                    print(f"[{self.hand_name}] ç¼–ç å™¨æ ¡å‡†æ–‡ä»¶: {calib_file}")
                else:
                    print(f"[{self.hand_name}] âš ï¸ æ ¡å‡†æ–‡ä»¶ä¸å­˜åœ¨: {calib_file}")
        
        use_encoder = False
        if self.encoder:
            print(f"[{self.hand_name}] å°è¯•è¿æ¥ç¼–ç å™¨ {port} @ {baudrate}...")
            use_encoder = self.encoder.open()
            if use_encoder:
                print(f"[{self.hand_name}] âœ“ ç¼–ç å™¨è¿æ¥æˆåŠŸ")
            else:
                print(f"[{self.hand_name}] âŒ ç¼–ç å™¨è¿æ¥å¤±è´¥")
                # å°è¯•è¯Šæ–­é—®é¢˜
                if not minimalmodbus:
                    print(f"[{self.hand_name}]   åŸå› : minimalmodbus æœªå®‰è£…")
                elif not os.path.exists(port):
                    print(f"[{self.hand_name}]   åŸå› : ä¸²å£ {port} ä¸å­˜åœ¨")
                elif not os.access(port, os.R_OK | os.W_OK):
                    print(f"[{self.hand_name}]   åŸå› : ä¸²å£ {port} æƒé™ä¸è¶³")
                else:
                    print(f"[{self.hand_name}]   åŸå› : å¯èƒ½æ˜¯è®¾å¤‡åœ°å€æˆ–æ³¢ç‰¹ç‡ä¸åŒ¹é…")
        
        # å¦‚æœä»YAMLè®¾ç½®äº†æ ¡å‡†å‚æ•°ï¼Œåœ¨openä¹‹åéœ€è¦é‡æ–°è®¾ç½®ï¼ˆå› ä¸ºopenä¼šè°ƒç”¨_load_calibrationï¼‰
        if use_encoder and calibration_cfg:
            self.encoder.angle_zero = calibration_cfg.get('angle_zero', 0.0)
            self.encoder.calibrated = calibration_cfg.get('calibrated', False)
            if self.encoder.calibrated:
                print(f"[{self.hand_name}] ç¼–ç å™¨æ ¡å‡†é›¶ç‚¹: {self.encoder.angle_zero:.2f}Â°")
        
        # å¯åŠ¨é‡‡é›†
        self.mono.start()
        self.stereo.start()
        if use_encoder:
            self.encoder.start()
            # ç­‰å¾…ä¸€ä¸‹ï¼Œç¡®ä¿ç¼–ç å™¨å¼€å§‹è¯»å–
            time.sleep(0.2)
            encoder_test = self.encoder.get_buffer()
            if encoder_test:
                print(f"[{self.hand_name}] âœ“ ç¼–ç å™¨æ­£åœ¨è¯»å–æ•°æ® ({len(encoder_test)} æ¡)")
            else:
                print(f"[{self.hand_name}] âš ï¸ ç¼–ç å™¨å·²å¯åŠ¨ï¼Œä½†ç¼“å†²åŒºä¸ºç©ºï¼ˆå¯èƒ½æ­£åœ¨åˆå§‹åŒ–ï¼‰")
        
        print(f"[{self.hand_name}] âœ“ ç›¸æœºå·²å¯åŠ¨")
        
        self._ready = True
    
    def _load_stereo_rectification(self):
        """åŠ è½½ç«‹ä½“æ ¡æ­£å‚æ•°ï¼ˆä¼˜å…ˆä»config.yamlè¯»å–ï¼Œå¦åˆ™ä»JSONæ–‡ä»¶è¯»å–ï¼‰"""
        stereo_cfg = self.config.get('stereo', {})
        
        # ç¡®å®šæ˜¯å·¦æ‰‹è¿˜æ˜¯å³æ‰‹
        hand_name = self.hand_name.lower()
        is_left = 'left' in hand_name
        hand_key = 'left' if is_left else 'right'
        
        calib = None
        calib_source = None
        
        # ä¼˜å…ˆä»config.yamlè¯»å–æ ‡å®šå‚æ•°
        calibration_cfg = stereo_cfg.get('calibration', {})
        if calibration_cfg and calibration_cfg.get('calibrated', False):
            try:
                # ä»YAMLé…ç½®æ„å»ºæ ‡å®šå­—å…¸
                calib = {
                    'left_camera_matrix': calibration_cfg['left_camera_matrix'],
                    'left_distortion': calibration_cfg['left_distortion'],
                    'right_camera_matrix': calibration_cfg['right_camera_matrix'],
                    'right_distortion': calibration_cfg['right_distortion'],
                    'rectify_rotation_left': calibration_cfg['rectify_rotation_left'],
                    'rectify_rotation_right': calibration_cfg['rectify_rotation_right'],
                    'projection_left': calibration_cfg['projection_left'],
                    'projection_right': calibration_cfg['projection_right'],
                    'image_size': calibration_cfg['image_size'],
                    'baseline_mm': calibration_cfg.get('baseline_mm', 0),
                    'reprojection_error': calibration_cfg.get('reprojection_error', 0),
                }
                calib_source = "config.yaml"
            except Exception as e:
                print(f"[{self.hand_name}] âš ï¸ ä»config.yamlè¯»å–æ ‡å®šå‚æ•°å¤±è´¥: {e}")
                calib = None
        
        # å¦‚æœconfig.yamlä¸­æ²¡æœ‰ï¼Œå°è¯•ä»JSONæ–‡ä»¶è¯»å–
        if calib is None:
            calib_file = stereo_cfg.get('calibration_file', '')
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œå°è¯•é»˜è®¤è·¯å¾„ï¼ˆæ ¹æ®å·¦å³æ‰‹ï¼‰
            if not calib_file:
                # é»˜è®¤æŸ¥æ‰¾æ ‡å®šæ–‡ä»¶ï¼ˆæ ¹æ®å·¦å³æ‰‹ï¼‰
                default_calib_paths = [
                    os.path.join(os.path.dirname(__file__), "stereo_calibration", hand_key, f"stereo_calibration_{hand_key}.json"),
                    os.path.join(os.path.dirname(__file__), "..", "stereo_calibration", hand_key, f"stereo_calibration_{hand_key}.json"),
                    f"stereo_calibration/{hand_key}/stereo_calibration_{hand_key}.json",
                    # å…¼å®¹æ—§æ ¼å¼ï¼ˆå¦‚æœæ²¡æœ‰å·¦å³æ‰‹ç›®å½•ï¼ŒæŸ¥æ‰¾æ ¹ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼‰
                    os.path.join(os.path.dirname(__file__), "stereo_calibration", "stereo_calibration.json"),
                    os.path.join(os.path.dirname(__file__), "..", "stereo_calibration", "stereo_calibration.json"),
                    "stereo_calibration/stereo_calibration.json",
                ]
                for path in default_calib_paths:
                    if os.path.exists(path):
                        calib_file = path
                        break
            
            if calib_file and os.path.exists(calib_file):
                try:
                    with open(calib_file, 'r') as f:
                        calib = json.load(f)
                    calib_source = calib_file
                except Exception as e:
                    print(f"[{self.hand_name}] âš ï¸ åŠ è½½JSONæ ‡å®šæ–‡ä»¶å¤±è´¥: {e}")
                    calib = None
        
        # åº”ç”¨æ ‡å®šå‚æ•°
        if calib:
            try:
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                mtx_l = np.array(calib['left_camera_matrix'])
                dist_l = np.array(calib['left_distortion'])
                mtx_r = np.array(calib['right_camera_matrix'])
                dist_r = np.array(calib['right_distortion'])
                R1 = np.array(calib['rectify_rotation_left'])
                R2 = np.array(calib['rectify_rotation_right'])
                P1 = np.array(calib['projection_left'])
                P2 = np.array(calib['projection_right'])
                image_size = tuple(calib['image_size'])
                
                # è®¡ç®—æ ¡æ­£æ˜ å°„
                self.stereo_map1_l, self.stereo_map2_l = cv2.initUndistortRectifyMap(
                    mtx_l, dist_l, R1, P1, image_size, cv2.CV_16SC2
                )
                self.stereo_map1_r, self.stereo_map2_r = cv2.initUndistortRectifyMap(
                    mtx_r, dist_r, R2, P2, image_size, cv2.CV_16SC2
                )
                
                self.stereo_calibration = calib
                self.stereo_rectify_enabled = True
                
                print(f"[{self.hand_name}] âœ“ ç«‹ä½“æ ¡æ­£å·²åŠ è½½: {calib_source}")
                print(f"[{self.hand_name}]   åŸºçº¿è·ç¦»: {calib.get('baseline_mm', 0):.2f} mm")
                print(f"[{self.hand_name}]   é‡æŠ•å½±è¯¯å·®: {calib.get('reprojection_error', 0):.3f} åƒç´ ")
            except Exception as e:
                print(f"[{self.hand_name}] âš ï¸ åº”ç”¨ç«‹ä½“æ ¡æ­£å¤±è´¥: {e}")
                print(f"[{self.hand_name}]   å°†ä½¿ç”¨åŸå§‹å›¾åƒï¼ˆæœªæ ¡æ­£ï¼‰")
                self.stereo_rectify_enabled = False
        else:
            print(f"[{self.hand_name}] âš ï¸ æœªæ‰¾åˆ°ç«‹ä½“æ ¡æ­£å‚æ•°ï¼Œå°†ä½¿ç”¨åŸå§‹å›¾åƒ")
            print(f"[{self.hand_name}]   å¦‚éœ€æ ¡æ­£ï¼Œè¯·å…ˆè¿è¡Œæ ‡å®š: python stereo_calibration.py --calibrate --hand {hand_key}")
            self.stereo_rectify_enabled = False
    
    def _rectify_stereo(self, stereo_img: np.ndarray) -> np.ndarray:
        """å¯¹åŒç›®å›¾åƒåº”ç”¨ç«‹ä½“æ ¡æ­£"""
        if not self.stereo_rectify_enabled or self.stereo_map1_l is None:
            return stereo_img
        
        # åˆ†å‰²å·¦å³å›¾åƒ
        mid = stereo_img.shape[1] // 2
        left_raw = stereo_img[:, :mid]
        right_raw = stereo_img[:, mid:]
        
        # åº”ç”¨æ ¡æ­£
        left_rectified = cv2.remap(left_raw, self.stereo_map1_l, self.stereo_map2_l, cv2.INTER_LINEAR)
        right_rectified = cv2.remap(right_raw, self.stereo_map1_r, self.stereo_map2_r, cv2.INTER_LINEAR)
        
        # é‡æ–°æ‹¼æ¥
        rectified = np.hstack([left_rectified, right_rectified])
        return rectified
    
    def warmup_and_calibrate(self, warmup_time: float, calib_time: float):
        """é¢„çƒ­å¹¶æ ¡å‡†"""
        print(f"\n[{self.hand_name}] é¢„çƒ­ {warmup_time}s...")
        
        start = time.time()
        while time.time() - start < warmup_time:
            elapsed = time.time() - start
            s_fps = self.stereo.get_fps()
            m_fps = self.mono.get_fps()
            print(f"\r[{self.hand_name}] [{elapsed:.1f}s] S:{s_fps:.1f}fps M:{m_fps:.1f}fps", end="", flush=True)
            time.sleep(0.1)
        print()
        
        # æ¸…ç©ºé¢„çƒ­æ•°æ®
        self.stereo.clear_buffer()
        self.mono.clear_buffer()
        if self.encoder:
            self.encoder.clear_buffer()
        
        # æ ¡å‡†
        print(f"[{self.hand_name}] æ ¡å‡† {calib_time}s...")
        time.sleep(calib_time)
        
        stereo_data = self.stereo.get_buffer()
        mono_data = self.mono.get_buffer()
        encoder_data = self.encoder.get_buffer() if self.encoder else []
        
        offsets_sm = []
        offsets_se = []
        
        for s in stereo_data:
            if mono_data:
                best = min(mono_data, key=lambda x: abs(x.timestamp - s.timestamp))
                if abs(best.timestamp - s.timestamp) < 0.05:
                    offsets_sm.append((s.timestamp - best.timestamp) * 1000)
            
            if encoder_data:
                best = min(encoder_data, key=lambda x: abs(x.timestamp - s.timestamp))
                if abs(best.timestamp - s.timestamp) < 0.05:
                    offsets_se.append((s.timestamp - best.timestamp) * 1000)
        
        if offsets_sm:
            self.stereo_mono_offset_ms = np.median(offsets_sm)
        if offsets_se:
            self.stereo_encoder_offset_ms = np.median(offsets_se)
        
        print(f"[{self.hand_name}] âœ“ åç§»é‡: S-M={self.stereo_mono_offset_ms:.1f}ms, S-E={self.stereo_encoder_offset_ms:.1f}ms")
        
        # æ¸…ç©ºæ ¡å‡†æ•°æ®
        self.stereo.clear_buffer()
        self.mono.clear_buffer()
        if self.encoder:
            self.encoder.clear_buffer()
    
    def start_recording(self) -> bool:
        """å¼€å§‹å½•åˆ¶"""
        if not self._ready or self._recording:
            return False
        
        with self._record_lock:
            self._recorded_stereo.clear()
            self._recorded_mono.clear()
            self._recorded_encoder.clear()
            self._record_stats = {'frames': 0, 'last_print': time.time()}
            # é‡ç½®å¢é‡å¤åˆ¶ç´¢å¼•
            self._last_copied_idx = {'stereo': 0, 'mono': 0, 'encoder': 0}
        
        self.stereo.clear_buffer()
        self.mono.clear_buffer()
        if self.encoder:
            self.encoder.clear_buffer()
        
        self._record_start_ts = time.time()
        self._recording = True
        
        self._record_thread = threading.Thread(target=self._record_loop, daemon=True)
        self._record_thread.start()
        
        return True
    
    def _record_loop(self):
        """å½•åˆ¶å¾ªç¯ï¼ˆå¢é‡å¤åˆ¶ + å®æ—¶JPEGå‹ç¼©ä¼˜åŒ–ï¼‰"""
        import os
        
        process = None
        memory_warning_threshold = 3 * 1024 * 1024 * 1024  # 3GBè­¦å‘Šé˜ˆå€¼ï¼ˆé™ä½ä»¥æå‰é¢„è­¦ï¼‰
        if HAS_PSUTIL:
            try:
                process = psutil.Process(os.getpid())
            except:
                pass
        
        # JPEGå‹ç¼©å‚æ•°
        encode_params = [cv2.IMWRITE_JPEG_QUALITY, self._jpeg_quality]
        
        while self._recording:
            time.sleep(0.1)  # ä¿æŒ0.1ç§’é‡‡æ ·é—´éš”
            
            # è·å–å½“å‰ç¼“å†²åŒºï¼ˆå…¨é‡ï¼‰
            s_data = self.stereo.get_buffer()
            m_data = self.mono.get_buffer()
            e_data = self.encoder.get_buffer() if self.encoder else []
            
            # å¢é‡å¤åˆ¶ï¼šåªå¤„ç†æ–°å¢çš„å¸§
            new_stereo = [f for f in s_data if f.idx > self._last_copied_idx['stereo']]
            new_mono = [f for f in m_data if f.idx > self._last_copied_idx['mono']]
            new_encoder = [f for f in e_data if f.idx > self._last_copied_idx['encoder']]
            
            # å®æ—¶JPEGå‹ç¼©æ–°å¸§
            compressed_stereo = []
            for frame in new_stereo:
                success, jpeg_data = cv2.imencode('.jpg', frame.data, encode_params)
                if success:
                    # å°†JPEGå­—èŠ‚æ•°æ®åŒ…è£…ä¸ºSensorFrame
                    compressed_stereo.append(SensorFrame(frame.timestamp, np.asarray(jpeg_data, dtype=np.uint8), frame.idx))
            
            compressed_mono = []
            for frame in new_mono:
                success, jpeg_data = cv2.imencode('.jpg', frame.data, encode_params)
                if success:
                    compressed_mono.append(SensorFrame(frame.timestamp, np.asarray(jpeg_data, dtype=np.uint8), frame.idx))
            
            # è¿½åŠ åˆ°å½•åˆ¶åˆ—è¡¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
            with self._record_lock:
                self._recorded_stereo.extend(compressed_stereo)
                self._recorded_mono.extend(compressed_mono)
                self._recorded_encoder.extend(new_encoder)
                
                current_frames = len(self._recorded_stereo)
                
                # æ›´æ–°ç»Ÿè®¡
                if compressed_stereo:
                    self._record_stats['frames'] += len(compressed_stereo)
            
            # æ›´æ–°ç´¢å¼•
            if new_stereo:
                self._last_copied_idx['stereo'] = new_stereo[-1].idx
            if new_mono:
                self._last_copied_idx['mono'] = new_mono[-1].idx
            if new_encoder:
                self._last_copied_idx['encoder'] = new_encoder[-1].idx
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§å¸§æ•°é™åˆ¶
            if current_frames >= self._max_record_frames:
                print(f"\nâš ï¸ [{self.hand_name}] è¾¾åˆ°æœ€å¤§å½•åˆ¶å¸§æ•° {self._max_record_frames}ï¼Œè‡ªåŠ¨åœæ­¢")
                self._recording = False
                break
            
            # å®šæœŸæ‰“å°è¿›åº¦
            now = time.time()
            if now - self._record_stats['last_print'] >= 5.0:
                elapsed = now - self._record_start_ts
                total_fps = self._record_stats['frames'] / elapsed if elapsed > 0 else 0
                
                # è·å–åŒç›®å’Œå•ç›®æ‘„åƒå¤´çš„å®é™…å¸§ç‡
                stereo_fps = self.stereo.get_fps()
                mono_fps = self.mono.get_fps()
                encoder_count = len(self._recorded_encoder)
                
                # æ£€æŸ¥å†…å­˜ä½¿ç”¨
                if process:
                    try:
                        mem_info = process.memory_info()
                        mem_mb = mem_info.rss / (1024 * 1024)
                        mem_gb = mem_mb / 1024
                        
                        # å†…å­˜è­¦å‘Šï¼ˆè‡ªåŠ¨åœæ­¢ï¼‰
                        if mem_info.rss > memory_warning_threshold:
                            print(f"\nâš ï¸ [{self.hand_name}] å†…å­˜ä½¿ç”¨è¿‡é«˜: {mem_gb:.1f}GBï¼Œè‡ªåŠ¨åœæ­¢å½•åˆ¶")
                            self._recording = False
                            break
                        
                        print(f"[{self.hand_name}] å½•åˆ¶ä¸­: {current_frames} å¸§ ({elapsed:.1f}s) | æ€»FPS: {total_fps:.1f} | åŒç›®: {stereo_fps:.1f}fps | å•ç›®: {mono_fps:.1f}fps | encoder: {encoder_count} | å†…å­˜: {mem_gb:.1f}GB", end='\r')
                    except:
                        print(f"[{self.hand_name}] å½•åˆ¶ä¸­: {current_frames} å¸§ ({elapsed:.1f}s) | æ€»FPS: {total_fps:.1f} | åŒç›®: {stereo_fps:.1f}fps | å•ç›®: {mono_fps:.1f}fps | encoder: {encoder_count}", end='\r')
                else:
                    print(f"[{self.hand_name}] å½•åˆ¶ä¸­: {current_frames} å¸§ ({elapsed:.1f}s) | æ€»FPS: {total_fps:.1f} | åŒç›®: {stereo_fps:.1f}fps | å•ç›®: {mono_fps:.1f}fps | encoder: {encoder_count}", end='\r')
                
                self._record_stats['last_print'] = now
            
            # æ¸…ç©ºç¼“å†²åŒºï¼ˆä¸æ ‘è“æ´¾ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰
            self.stereo.clear_buffer()
            self.mono.clear_buffer()
            if self.encoder:
                self.encoder.clear_buffer()
    
    def get_current_frame(self) -> Optional[HandFrame]:
        """è·å–å½“å‰å¸§ï¼ˆç”¨äºå®æ—¶é¢„è§ˆï¼Œåº”ç”¨ç«‹ä½“æ ¡æ­£ï¼‰"""
        if not self._ready:
            return None
        
        s_data = self.stereo.get_buffer()
        m_data = self.mono.get_buffer()
        e_data = self.encoder.get_buffer() if self.encoder else []
        
        if not s_data or not m_data:
            return None
        
        latest_s = s_data[-1]
        best_m = min(m_data, key=lambda x: abs(x.timestamp - latest_s.timestamp))
        
        angle = 0.0
        enc_ts = latest_s.timestamp
        if e_data:
            best_e = min(e_data, key=lambda x: abs(x.timestamp - latest_s.timestamp))
            angle = best_e.data
            enc_ts = best_e.timestamp
        
        # åº”ç”¨ç«‹ä½“æ ¡æ­£
        stereo_rectified = self._rectify_stereo(latest_s.data)
        
        return HandFrame(
            stereo=stereo_rectified,
            mono=best_m.data,
            angle=angle,
            timestamp=latest_s.timestamp,
            stereo_ts=latest_s.timestamp,
            mono_ts=best_m.timestamp,
            encoder_ts=enc_ts,
            idx=0
        )
    
    def stop_recording(self) -> List[HandFrame]:
        """åœæ­¢å½•åˆ¶å¹¶è¿”å›å¯¹é½çš„æ•°æ®ï¼ˆåˆ†æ‰¹å¤„ç†ä¼˜åŒ–å†…å­˜ï¼‰"""
        if not self._recording:
            return []
        
        print(f"\n[{self.hand_name}] åœæ­¢å½•åˆ¶ï¼Œå¤„ç†æ•°æ®...")
        self._recording = False
        if self._record_thread:
            self._record_thread.join(timeout=2)
        
        # æ”¶é›†æœ€åçš„æ•°æ®ï¼ˆå¢é‡å¼ï¼‰
        s_data = self.stereo.get_buffer()
        m_data = self.mono.get_buffer()
        e_data = self.encoder.get_buffer() if self.encoder else []
        
        # JPEGå‹ç¼©å‚æ•°
        encode_params = [cv2.IMWRITE_JPEG_QUALITY, self._jpeg_quality]
        
        # å¢é‡å¤„ç†æœ€åçš„æ–°æ•°æ®
        new_stereo = [f for f in s_data if f.idx > self._last_copied_idx['stereo']]
        new_mono = [f for f in m_data if f.idx > self._last_copied_idx['mono']]
        new_encoder = [f for f in e_data if f.idx > self._last_copied_idx['encoder']]
        
        # å‹ç¼©æœ€åçš„æ–°å¸§
        compressed_stereo = []
        for frame in new_stereo:
            success, jpeg_data = cv2.imencode('.jpg', frame.data, encode_params)
            if success:
                compressed_stereo.append(SensorFrame(frame.timestamp, np.asarray(jpeg_data, dtype=np.uint8), frame.idx))
        
        compressed_mono = []
        for frame in new_mono:
            success, jpeg_data = cv2.imencode('.jpg', frame.data, encode_params)
            if success:
                compressed_mono.append(SensorFrame(frame.timestamp, np.asarray(jpeg_data, dtype=np.uint8), frame.idx))
        
        with self._record_lock:
            # æ·»åŠ æœ€åçš„å‹ç¼©æ•°æ®
            self._recorded_stereo.extend(compressed_stereo)
            self._recorded_mono.extend(compressed_mono)
            self._recorded_encoder.extend(new_encoder)
            
            # å¤åˆ¶æ•°æ®ï¼ˆæ³¨æ„ï¼šç°åœ¨æ˜¯JPEGå‹ç¼©çš„æ•°æ®ï¼‰
            stereo_data = list(self._recorded_stereo)
            mono_data = list(self._recorded_mono)
            encoder_data = list(self._recorded_encoder)
        
        # è®¡ç®—å½•åˆ¶ç»Ÿè®¡ä¿¡æ¯
        record_duration = time.time() - self._record_start_ts
        stereo_fps = len(stereo_data) / record_duration if record_duration > 0 else 0
        mono_fps = len(mono_data) / record_duration if record_duration > 0 else 0
        encoder_fps = len(encoder_data) / record_duration if record_duration > 0 else 0
        
        print(f"[{self.hand_name}] åŸå§‹æ•°æ®: {len(stereo_data)} stereo, {len(mono_data)} mono, {len(encoder_data)} encoder")
        print(f"[{self.hand_name}] å½•åˆ¶æ—¶é•¿: {record_duration:.2f}s")
        print(f"[{self.hand_name}] å®é™…å¸§ç‡: åŒç›®={stereo_fps:.2f}fps, å•ç›®={mono_fps:.2f}fps, ç¼–ç å™¨={encoder_fps:.2f}fps")
        
        # åˆ†æ‰¹å¯¹é½æ•°æ®ï¼ˆä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼‰
        # ä½¿ç”¨è¾ƒå®½æ¾çš„æ—¶é—´å·®å®¹é™ï¼ˆ200msï¼‰ä»¥é€‚åº”ä¸åŒå¸§ç‡
        aligned = self._align_data_batch(stereo_data, mono_data, encoder_data, max_time_diff_ms=200.0)
        
        # æ¸…ç†åŸå§‹æ•°æ®ï¼Œé‡Šæ”¾å†…å­˜
        del stereo_data, mono_data, encoder_data
        
        print(f"[{self.hand_name}] å¯¹é½å: {len(aligned)} å¸§")
        
        return aligned
    
    def _align_data(self, stereo_data: List[SensorFrame], 
                   mono_data: List[SensorFrame],
                   encoder_data: List[SensorFrame],
                   max_time_diff_ms: float = 50.0) -> List[HandFrame]:
        """å¯¹é½æ•°æ®ï¼ˆåº”ç”¨ç«‹ä½“æ ¡æ­£ï¼‰- æ—§ç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹æ€§"""
        return self._align_data_batch(stereo_data, mono_data, encoder_data, max_time_diff_ms)
    
    def _align_data_batch(self, stereo_data: List[SensorFrame], 
                          mono_data: List[SensorFrame],
                          encoder_data: List[SensorFrame],
                          max_time_diff_ms: float = 50.0,
                          batch_size: int = 100) -> List[HandFrame]:
        """åˆ†æ‰¹å¯¹é½æ•°æ®ï¼ˆä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå¤„ç†JPEGå‹ç¼©æ•°æ®ï¼‰"""
        aligned = []
        n_total = len(stereo_data)
        
        # å¦‚æœæ•°æ®é‡ä¸å¤§ï¼Œç›´æ¥å¤„ç†
        if n_total <= batch_size:
            for s in stereo_data:
                mono_target = s.timestamp - self.stereo_mono_offset_ms / 1000.0
                encoder_target = s.timestamp - self.stereo_encoder_offset_ms / 1000.0
                
                mono = None
                if mono_data:
                    best = min(mono_data, key=lambda x: abs(x.timestamp - mono_target))
                    if abs(best.timestamp - mono_target) * 1000 <= max_time_diff_ms:
                        mono = best
                
                enc = None
                if encoder_data:
                    best = min(encoder_data, key=lambda x: abs(x.timestamp - encoder_target))
                    if abs(best.timestamp - encoder_target) * 1000 <= max_time_diff_ms:
                        enc = best
                
                # å…è®¸æ²¡æœ‰ç¼–ç å™¨æ•°æ®çš„æƒ…å†µï¼ˆä½¿ç”¨é»˜è®¤è§’åº¦0ï¼‰
                if mono:
                    # è§£å‹JPEGæ•°æ®
                    stereo_img = cv2.imdecode(s.data, cv2.IMREAD_COLOR)
                    mono_img = cv2.imdecode(mono.data, cv2.IMREAD_COLOR)
                    
                    # åº”ç”¨ç«‹ä½“æ ¡æ­£
                    stereo_rectified = self._rectify_stereo(stereo_img)
                    
                    aligned.append(HandFrame(
                        stereo=stereo_rectified,
                        mono=mono_img,
                        angle=enc.data if enc else 0.0,
                        timestamp=s.timestamp,
                        stereo_ts=s.timestamp,
                        mono_ts=mono.timestamp,
                        encoder_ts=enc.timestamp if enc else s.timestamp,
                        idx=len(aligned) + 1
                    ))
        else:
            # åˆ†æ‰¹å¤„ç†
            for i in range(0, n_total, batch_size):
                batch_end = min(i + batch_size, n_total)
                batch_stereo = stereo_data[i:batch_end]
                
                batch_aligned = []
                for s in batch_stereo:
                    mono_target = s.timestamp - self.stereo_mono_offset_ms / 1000.0
                    encoder_target = s.timestamp - self.stereo_encoder_offset_ms / 1000.0
                    
                    mono = None
                    if mono_data:
                        best = min(mono_data, key=lambda x: abs(x.timestamp - mono_target))
                        if abs(best.timestamp - mono_target) * 1000 <= max_time_diff_ms:
                            mono = best
                    
                    enc = None
                    if encoder_data:
                        best = min(encoder_data, key=lambda x: abs(x.timestamp - encoder_target))
                        if abs(best.timestamp - encoder_target) * 1000 <= max_time_diff_ms:
                            enc = best
                    
                    # å…è®¸æ²¡æœ‰ç¼–ç å™¨æ•°æ®çš„æƒ…å†µï¼ˆä½¿ç”¨é»˜è®¤è§’åº¦0ï¼‰
                    if mono:
                        # è§£å‹JPEGæ•°æ®
                        stereo_img = cv2.imdecode(s.data, cv2.IMREAD_COLOR)
                        mono_img = cv2.imdecode(mono.data, cv2.IMREAD_COLOR)
                        
                        # åº”ç”¨ç«‹ä½“æ ¡æ­£
                        stereo_rectified = self._rectify_stereo(stereo_img)
                        
                        batch_aligned.append(HandFrame(
                            stereo=stereo_rectified,
                            mono=mono_img,
                            angle=enc.data if enc else 0.0,
                            timestamp=s.timestamp,
                            stereo_ts=s.timestamp,
                            mono_ts=mono.timestamp,
                            encoder_ts=enc.timestamp if enc else s.timestamp,
                        idx=len(aligned) + len(batch_aligned) + 1
                    ))
                
                aligned.extend(batch_aligned)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (batch_end / n_total) * 100
                print(f"[{self.hand_name}] å¯¹é½è¿›åº¦: {batch_end}/{n_total} ({progress:.1f}%)", end='\r')
            
            print()  # æ¢è¡Œ
        
        return aligned
    
    def stop(self):
        """åœæ­¢"""
        self._recording = False
        self._running = False
        self._ready = False
        
        if self._record_thread:
            self._record_thread.join(timeout=2)
        
        if self.stereo:
            self.stereo.stop()
        if self.mono:
            self.mono.stop()
        if self.encoder:
            self.encoder.stop()
        
        print(f"[{self.hand_name}] å·²åœæ­¢")


class DualHandCollector:
    """åŒæ‰‹åŒæ­¥æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, config_path: str):
        self.config_path = config_path
        self.config = self._load_config()
        
        self.left: Optional[HandCollector] = None
        self.right: Optional[HandCollector] = None
        
        self._ready = False
        self._running = False
        self._recording = False
    
    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®"""
        with open(self.config_path, 'r') as f:
            return yaml.safe_load(f)
    
    @property
    def is_ready(self) -> bool:
        return self._ready
    
    @property
    def is_recording(self) -> bool:
        return self._recording
    
    def start(self) -> bool:
        """å¯åŠ¨æ”¶é›†å™¨"""
        if self._running:
            return True
        
        self._running = True
        self._ready = False
        
        # åˆå§‹åŒ–å·¦å³æ‰‹æ”¶é›†å™¨
        left_cfg = self.config.get('left_hand', {})
        right_cfg = self.config.get('right_hand', {})
        
        self.left = HandCollector(left_cfg, "LEFT")
        self.right = HandCollector(right_cfg, "RIGHT")
        
        # å¯åŠ¨
        self.left.start()
        self.right.start()
        
        # ç­‰å¾…å°±ç»ª
        if not self.left.wait_ready() or not self.right.wait_ready():
            print("âŒ åˆå§‹åŒ–å¤±è´¥")
            return False
        
        # é¢„çƒ­å’Œæ ¡å‡†
        sync_cfg = self.config.get('sync', {})
        warmup_time = sync_cfg.get('warmup_time', 1.0)
        calib_time = sync_cfg.get('calib_time', 0.5)
        
        self.left.warmup_and_calibrate(warmup_time, calib_time)
        self.right.warmup_and_calibrate(warmup_time, calib_time)
        
        self._ready = True
        print("\nâœ… åŒæ‰‹æ”¶é›†å™¨å°±ç»ª")
        return True
    
    def wait_ready(self, timeout: float = 60.0) -> bool:
        """ç­‰å¾…å°±ç»ª"""
        start = time.time()
        while not self._ready and (time.time() - start) < timeout:
            time.sleep(0.1)
        return self._ready
    
    def start_recording(self) -> bool:
        """å¼€å§‹å½•åˆ¶"""
        if not self._ready or self._recording:
            return False
        
        self._recording = True
        self.left.start_recording()
        self.right.start_recording()
        
        print("ğŸ”´ å¼€å§‹å½•åˆ¶åŒæ‰‹æ•°æ®...")
        return True
    
    def stop_recording(self) -> List[DualHandFrame]:
        """åœæ­¢å½•åˆ¶å¹¶è¿”å›å¯¹é½çš„åŒæ‰‹æ•°æ®"""
        if not self._recording:
            return []
        
        self._recording = False
        
        # è·å–å·¦å³æ‰‹æ•°æ®
        left_data = self.left.stop_recording()
        right_data = self.right.stop_recording()
        
        # å¯¹é½åŒæ‰‹æ•°æ®
        aligned = self._align_hands(left_data, right_data)
        
        print(f"\nåŒæ‰‹å¯¹é½å®Œæˆ: {len(aligned)} å¸§")
        print(f"  å·¦æ‰‹: {len(left_data)} å¸§")
        print(f"  å³æ‰‹: {len(right_data)} å¸§")
        
        return aligned
    
    def _align_hands(self, left_data: List[HandFrame], 
                    right_data: List[HandFrame],
                    max_time_diff_ms: float = 50.0) -> List[DualHandFrame]:
        """å¯¹é½å·¦å³æ‰‹æ•°æ®"""
        aligned = []
        
        # ä»¥å·¦æ‰‹æ•°æ®ä¸ºåŸºå‡†å¯¹é½
        for left_frame in left_data:
            target_ts = left_frame.timestamp
            
            # æ‰¾åˆ°æœ€æ¥è¿‘çš„å³æ‰‹å¸§
            best_right = None
            if right_data:
                best_right = min(right_data, key=lambda x: abs(x.timestamp - target_ts))
                if abs(best_right.timestamp - target_ts) * 1000 > max_time_diff_ms:
                    best_right = None
            
            if best_right:
                aligned.append(DualHandFrame(
                    left=left_frame,
                    right=best_right,
                    timestamp=target_ts,
                    idx=len(aligned) + 1
                ))
        
        return aligned
    
    def stop(self):
        """åœæ­¢"""
        self._recording = False
        self._running = False
        self._ready = False
        
        if self.left:
            self.left.stop()
        if self.right:
            self.right.stop()
        
        print("åŒæ‰‹æ”¶é›†å™¨å·²åœæ­¢")


def save_dual_hand_data(data: List[DualHandFrame], output_dir: str,
                        jpeg_quality: int = 85) -> str:
    """ä¿å­˜åŒæ‰‹æ•°æ®åˆ°HDF5ï¼ˆæµå¼å†™å…¥ä¼˜åŒ–å†…å­˜ï¼‰"""
    if not data:
        print("âŒ æ— æ•°æ®")
        return None
    
    if not HAS_H5PY:
        print("âŒ h5py æœªå®‰è£…ï¼Œæ— æ³•ä¿å­˜æ•°æ®")
        return None
    
    from datetime import datetime
    import h5py
    
    os.makedirs(output_dir, exist_ok=True)
    prefix = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_dual_hand_data.h5"
    filepath = os.path.join(output_dir, filename)
    
    n_frames = len(data)
    print(f"\nä¿å­˜åŒæ‰‹æ•°æ®: {filepath}")
    print(f"  å¸§æ•°: {n_frames}")
    
    start_time = time.time()
    
    # æµå¼å†™å…¥HDF5ï¼ˆé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜ï¼‰
    encode_params = [cv2.IMWRITE_JPEG_QUALITY, jpeg_quality]
    
    print("  å†™å…¥HDF5ï¼ˆæµå¼ï¼‰...")
    write_start = time.time()
    
    with h5py.File(filepath, 'w', libver='latest') as f:
        # å…ƒæ•°æ®
        f.attrs['n_frames'] = n_frames
        f.attrs['left_stereo_shape'] = data[0].left.stereo.shape
        f.attrs['left_mono_shape'] = data[0].left.mono.shape
        f.attrs['right_stereo_shape'] = data[0].right.stereo.shape
        f.attrs['right_mono_shape'] = data[0].right.mono.shape
        f.attrs['jpeg_quality'] = jpeg_quality
        f.attrs['created_at'] = datetime.now().isoformat()
        
        # åˆ›å»ºæ•°æ®é›†ï¼ˆä½¿ç”¨å¯å˜é•¿åº¦æ•°æ®ç±»å‹ï¼‰
        dt = h5py.special_dtype(vlen=np.uint8)
        
        # åˆ›å»ºæ•°æ®é›†ï¼ˆé¢„å…ˆåˆ†é…ç©ºé—´ï¼‰
        left_stereo_ds = f.create_dataset('left_stereo_jpeg', (n_frames,), dtype=dt)
        left_mono_ds = f.create_dataset('left_mono_jpeg', (n_frames,), dtype=dt)
        right_stereo_ds = f.create_dataset('right_stereo_jpeg', (n_frames,), dtype=dt)
        right_mono_ds = f.create_dataset('right_mono_jpeg', (n_frames,), dtype=dt)
        
        left_angles = np.zeros(n_frames, dtype=np.float32)
        left_timestamps = np.zeros(n_frames, dtype=np.float64)
        right_angles = np.zeros(n_frames, dtype=np.float32)
        right_timestamps = np.zeros(n_frames, dtype=np.float64)
        sync_timestamps = np.zeros(n_frames, dtype=np.float64)
        
        # åˆ†æ‰¹å¤„ç†å’Œå†™å…¥ï¼ˆæ¯æ‰¹100å¸§ï¼‰
        batch_size = 100
        for i in range(0, n_frames, batch_size):
            batch_end = min(i + batch_size, n_frames)
            batch_data = data[i:batch_end]
            
            for j, frame in enumerate(batch_data):
                idx = i + j
                
                # å‹ç¼©å›¾åƒï¼ˆç«‹å³å†™å…¥ï¼Œä¸ä¿å­˜åˆ°åˆ—è¡¨ï¼‰
                success_ls, ls = cv2.imencode('.jpg', frame.left.stereo, encode_params)
                success_lm, lm = cv2.imencode('.jpg', frame.left.mono, encode_params)
                success_rs, rs = cv2.imencode('.jpg', frame.right.stereo, encode_params)
                success_rm, rm = cv2.imencode('.jpg', frame.right.mono, encode_params)
                
                if not (success_ls and success_lm and success_rs and success_rm):
                    print(f"\nâš ï¸ è­¦å‘Š: ç¬¬ {idx} å¸§å›¾åƒå‹ç¼©å¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # å¯¹äºå¯å˜é•¿åº¦æ•°æ®ç±»å‹ï¼Œç›´æ¥ä¼ é€’numpyæ•°ç»„ï¼ˆh5pyä¼šè‡ªåŠ¨å¤„ç†ï¼‰
                left_stereo_ds[idx] = ls
                left_mono_ds[idx] = lm
                right_stereo_ds[idx] = rs
                right_mono_ds[idx] = rm
                
                left_angles[idx] = frame.left.angle
                left_timestamps[idx] = frame.left.timestamp
                right_angles[idx] = frame.right.angle
                right_timestamps[idx] = frame.right.timestamp
                sync_timestamps[idx] = frame.timestamp
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = (batch_end / n_frames) * 100
            print(f"  è¿›åº¦: {batch_end}/{n_frames} ({progress:.1f}%)", end='\r')
        
        print()  # æ¢è¡Œ
        
        # å†™å…¥è§’åº¦å’Œæ—¶é—´æˆ³æ•°æ®
        f.create_dataset('left_angles', data=left_angles, dtype=np.float32)
        f.create_dataset('left_timestamps', data=left_timestamps, dtype=np.float64)
        f.create_dataset('right_angles', data=right_angles, dtype=np.float32)
        f.create_dataset('right_timestamps', data=right_timestamps, dtype=np.float64)
        f.create_dataset('sync_timestamps', data=sync_timestamps, dtype=np.float64)
    
    write_time = time.time() - write_start
    total_time = time.time() - start_time
    
    file_size = os.path.getsize(filepath) / (1024 * 1024)
    
    print(f"  å†™å…¥è€—æ—¶: {write_time:.2f}s")
    print(f"  æ€»è€—æ—¶: {total_time:.2f}s")
    print(f"  æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
    print(f"âœ… ä¿å­˜å®Œæˆ: {filepath}")
    
    return filepath


def visualize_hand(collector: HandCollector, hand_name: str):
    """å¯è§†åŒ–å•æ‰‹æ•°æ®"""
    print(f"\n[{hand_name}] å¼€å§‹å¯è§†åŒ–ï¼ˆæŒ‰ 'q' é€€å‡ºï¼‰...")
    
    window_name = f"{hand_name} Hand - Press 'q' to quit"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    
    angle_history = []
    max_history = 100
    
    try:
        while True:
            frame = collector.get_current_frame()
            
            if frame is None:
                time.sleep(0.01)
                continue
            
            # è·å–å›¾åƒ
            stereo_img = frame.stereo.copy()
            mono_img = frame.mono.copy()
            angle = frame.angle
            
            # æ›´æ–°è§’åº¦å†å²
            angle_history.append(angle)
            if len(angle_history) > max_history:
                angle_history.pop(0)
            
            # åˆ†å‰²åŒç›®å›¾åƒï¼ˆå‡è®¾æ˜¯å·¦å³æ‹¼æ¥çš„ï¼‰
            stereo_h, stereo_w = stereo_img.shape[:2]
            if stereo_w > stereo_h:
                # æ°´å¹³æ‹¼æ¥ï¼šå·¦å³
                left_img = stereo_img[:, :stereo_w//2]
                right_img = stereo_img[:, stereo_w//2:]
            else:
                # å‚ç›´æ‹¼æ¥ï¼šä¸Šä¸‹
                left_img = stereo_img[:stereo_h//2, :]
                right_img = stereo_img[stereo_h//2:, :]
            
            # ä¿æŒåŸå§‹å°ºå¯¸ï¼Œä¸è¿›è¡Œresize
            mono_display = mono_img.copy()
            left_display = left_img.copy()
            right_display = right_img.copy()
            
            # åˆ›å»ºè§’åº¦æ˜¾ç¤ºå›¾åƒï¼ˆé«˜åº¦ä¸mono_displayåŒ¹é…ï¼‰
            angle_img = np.zeros((mono_display.shape[0], 400, 3), dtype=np.uint8)
            
            # ç»˜åˆ¶å½“å‰è§’åº¦
            angle_text = f"Angle: {angle:.2f}Â°"
            cv2.putText(angle_img, angle_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # ç»˜åˆ¶è§’åº¦å†å²æ›²çº¿
            if len(angle_history) > 1:
                points = []
                angle_img_h = angle_img.shape[0]
                angle_img_w = angle_img.shape[1]
                for i, a in enumerate(angle_history):
                    x = int((i / max(len(angle_history) - 1, 1)) * (angle_img_w - 20) + 10)
                    # è§’åº¦èŒƒå›´å‡è®¾æ˜¯-180åˆ°180ï¼Œæ˜ å°„åˆ°å›¾åƒé«˜åº¦
                    y = int(angle_img_h - 20 - (a + 180) / 360 * (angle_img_h - 40))
                    points.append((x, y))
                
                for i in range(len(points) - 1):
                    cv2.line(angle_img, points[i], points[i+1], (0, 255, 255), 2)
            
            # ç»„åˆæ˜¾ç¤ºå›¾åƒ
            # ä¸Šæ’ï¼šåŒç›®å·¦å³
            stereo_row = np.hstack([left_display, right_display])
            
            # ä¸‹æ’ï¼šå•ç›®å’Œè§’åº¦
            bottom_row = np.hstack([mono_display, angle_img])
            
            # å¦‚æœå®½åº¦ä¸ä¸€è‡´ï¼Œç”¨é»‘è‰²å¡«å……è¾ƒå°çš„å›¾åƒ
            if stereo_row.shape[1] != bottom_row.shape[1]:
                target_width = max(stereo_row.shape[1], bottom_row.shape[1])
                if stereo_row.shape[1] < target_width:
                    # åœ¨å³ä¾§å¡«å……é»‘è‰²
                    padding = np.zeros((stereo_row.shape[0], target_width - stereo_row.shape[1], 3), dtype=np.uint8)
                    stereo_row = np.hstack([stereo_row, padding])
                if bottom_row.shape[1] < target_width:
                    # åœ¨å³ä¾§å¡«å……é»‘è‰²
                    padding = np.zeros((bottom_row.shape[0], target_width - bottom_row.shape[1], 3), dtype=np.uint8)
                    bottom_row = np.hstack([bottom_row, padding])
            
            display = np.vstack([stereo_row, bottom_row])
            
            # æ·»åŠ æ ‡é¢˜
            title_height = 30
            title_img = np.zeros((title_height, display.shape[1], 3), dtype=np.uint8)
            title_text = f"{hand_name} Hand - Stereo (Left/Right) | Mono | Angle"
            cv2.putText(title_img, title_text, (10, 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            display = np.vstack([title_img, display])
            
            # æ˜¾ç¤ºFPSå’Œæ—¶é—´æˆ³
            fps_text = f"FPS: {1.0 / (time.time() - getattr(visualize_hand, 'last_time', time.time())):.1f}"
            cv2.putText(display, fps_text, (10, display.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            visualize_hand.last_time = time.time()
            
            cv2.imshow(window_name, display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            
            time.sleep(0.01)
    
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyWindow(window_name)


def visualize_dual_hand(collector: DualHandCollector):
    """å¯è§†åŒ–åŒæ‰‹æ•°æ®"""
    print("\nåŒæ‰‹å¯è§†åŒ–ï¼ˆæŒ‰ 'q' é€€å‡ºï¼‰...")
    
    window_name = "Dual Hand - Press 'q' to quit"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    
    left_angle_history = []
    right_angle_history = []
    max_history = 100
    
    try:
        while True:
            left_frame = collector.left.get_current_frame() if collector.left else None
            right_frame = collector.right.get_current_frame() if collector.right else None
            
            if left_frame is None and right_frame is None:
                time.sleep(0.01)
                continue
            
            displays = []
            
            # å¤„ç†å·¦æ‰‹
            if left_frame:
                stereo_img = left_frame.stereo.copy()
                mono_img = left_frame.mono.copy()
                angle = left_frame.angle
                
                left_angle_history.append(angle)
                if len(left_angle_history) > max_history:
                    left_angle_history.pop(0)
                
                # åˆ†å‰²åŒç›®
                stereo_h, stereo_w = stereo_img.shape[:2]
                if stereo_w > stereo_h:
                    left_stereo = stereo_img[:, :stereo_w//2]
                    right_stereo = stereo_img[:, stereo_w//2:]
                else:
                    left_stereo = stereo_img[:stereo_h//2, :]
                    right_stereo = stereo_img[stereo_h//2:, :]
                
                # ä¿æŒåŸå§‹å°ºå¯¸ï¼Œä¸è¿›è¡Œresize
                mono_display = mono_img.copy()
                left_display = left_stereo.copy()
                right_display = right_stereo.copy()
                
                # è§’åº¦æ˜¾ç¤ºï¼ˆé«˜åº¦ä¸mono_displayåŒ¹é…ï¼‰
                angle_img = np.zeros((mono_display.shape[0], 300, 3), dtype=np.uint8)
                angle_img_h = angle_img.shape[0]
                angle_img_w = angle_img.shape[1]
                cv2.putText(angle_img, f"L: {angle:.2f}Â°", (10, 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                if len(left_angle_history) > 1:
                    points = []
                    for i, a in enumerate(left_angle_history):
                        x = int((i / max(len(left_angle_history) - 1, 1)) * (angle_img_w - 20) + 10)
                        y = int(angle_img_h - 20 - (a + 180) / 360 * (angle_img_h - 40))
                        points.append((x, y))
                    for i in range(len(points) - 1):
                        cv2.line(angle_img, points[i], points[i+1], (0, 255, 255), 2)
                
                left_row = np.hstack([left_display, right_display])
                left_bottom = np.hstack([mono_display, angle_img])
                if left_row.shape[1] != left_bottom.shape[1]:
                    target_w = max(left_row.shape[1], left_bottom.shape[1])
                    if left_row.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((left_row.shape[0], target_w - left_row.shape[1], 3), dtype=np.uint8)
                        left_row = np.hstack([left_row, padding])
                    if left_bottom.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((left_bottom.shape[0], target_w - left_bottom.shape[1], 3), dtype=np.uint8)
                        left_bottom = np.hstack([left_bottom, padding])
                
                left_display_full = np.vstack([left_row, left_bottom])
                displays.append(left_display_full)
            
            # å¤„ç†å³æ‰‹
            if right_frame:
                stereo_img = right_frame.stereo.copy()
                mono_img = right_frame.mono.copy()
                angle = right_frame.angle
                
                right_angle_history.append(angle)
                if len(right_angle_history) > max_history:
                    right_angle_history.pop(0)
                
                # åˆ†å‰²åŒç›®
                stereo_h, stereo_w = stereo_img.shape[:2]
                if stereo_w > stereo_h:
                    left_stereo = stereo_img[:, :stereo_w//2]
                    right_stereo = stereo_img[:, stereo_w//2:]
                else:
                    left_stereo = stereo_img[:stereo_h//2, :]
                    right_stereo = stereo_img[stereo_h//2:, :]
                
                # ä¿æŒåŸå§‹å°ºå¯¸ï¼Œä¸è¿›è¡Œresize
                mono_display = mono_img.copy()
                left_display = left_stereo.copy()
                right_display = right_stereo.copy()
                
                # è§’åº¦æ˜¾ç¤ºï¼ˆé«˜åº¦ä¸mono_displayåŒ¹é…ï¼‰
                angle_img = np.zeros((mono_display.shape[0], 300, 3), dtype=np.uint8)
                angle_img_h = angle_img.shape[0]
                angle_img_w = angle_img.shape[1]
                cv2.putText(angle_img, f"R: {angle:.2f}Â°", (10, 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                if len(right_angle_history) > 1:
                    points = []
                    for i, a in enumerate(right_angle_history):
                        x = int((i / max(len(right_angle_history) - 1, 1)) * (angle_img_w - 20) + 10)
                        y = int(angle_img_h - 20 - (a + 180) / 360 * (angle_img_h - 40))
                        points.append((x, y))
                    for i in range(len(points) - 1):
                        cv2.line(angle_img, points[i], points[i+1], (0, 255, 255), 2)
                
                right_row = np.hstack([left_display, right_display])
                right_bottom = np.hstack([mono_display, angle_img])
                if right_row.shape[1] != right_bottom.shape[1]:
                    target_w = max(right_row.shape[1], right_bottom.shape[1])
                    if right_row.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((right_row.shape[0], target_w - right_row.shape[1], 3), dtype=np.uint8)
                        right_row = np.hstack([right_row, padding])
                    if right_bottom.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((right_bottom.shape[0], target_w - right_bottom.shape[1], 3), dtype=np.uint8)
                        right_bottom = np.hstack([right_bottom, padding])
                
                right_display_full = np.vstack([right_row, right_bottom])
                displays.append(right_display_full)
            
            if displays:
                # ç»„åˆæ˜¾ç¤º
                if len(displays) == 2:
                    # åŒæ‰‹ï¼šä¸Šä¸‹æ’åˆ—
                    final_display = np.vstack(displays)
                else:
                    final_display = displays[0]
                
                # æ·»åŠ æ ‡é¢˜
                title_height = 30
                title_img = np.zeros((title_height, final_display.shape[1], 3), dtype=np.uint8)
                title_text = "Dual Hand Visualization - Press 'q' to quit"
                cv2.putText(title_img, title_text, (10, 20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
                final_display = np.vstack([title_img, final_display])
                
                cv2.imshow(window_name, final_display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            
            time.sleep(0.01)
    
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyWindow(window_name)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="åŒæ‰‹æ•°æ®æ”¶é›†å™¨")
    parser.add_argument("--config", "-c", type=str, default="config.yaml",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--mode", "-m", type=str, choices=['left', 'right', 'both'],
                       default='both', help="æµ‹è¯•æ¨¡å¼: left(å·¦æ‰‹), right(å³æ‰‹), both(åŒæ‰‹)")
    parser.add_argument("--visualize", "-v", action="store_true",
                       help="å¯ç”¨å¯è§†åŒ–æ¨¡å¼")
    parser.add_argument("--record", "-r", action="store_true",
                       help="å½•åˆ¶æ¨¡å¼ï¼ˆä¸å¯è§†åŒ–æ¨¡å¼äº’æ–¥ï¼‰")
    args = parser.parse_args()
    
    config_path = args.config
    if not os.path.isabs(config_path):
        config_path = os.path.join(os.path.dirname(__file__), config_path)
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å¼ï¼Œé»˜è®¤ä½¿ç”¨å¯è§†åŒ–
    if not args.visualize and not args.record:
        args.visualize = True
    
    try:
        if args.mode == 'both':
            # åŒæ‰‹æ¨¡å¼
            collector = DualHandCollector(config_path)
            collector.start()
            if not collector.wait_ready():
                print("âŒ åˆå§‹åŒ–å¤±è´¥")
                sys.exit(1)
            
            if args.visualize:
                visualize_dual_hand(collector)
            elif args.record:
                print("\næŒ‰å›è½¦é”®å¼€å§‹å½•åˆ¶...")
                input()
                collector.start_recording()
                print("å½•åˆ¶ä¸­... æŒ‰å›è½¦é”®åœæ­¢å½•åˆ¶")
                input()
                data = collector.stop_recording()
                if data:
                    save_cfg = collector.config.get('save', {})
                    output_dir = save_cfg.get('output_dir', './data')
                    jpeg_quality = save_cfg.get('jpeg_quality', 85)
                    save_dual_hand_data(data, output_dir, jpeg_quality)
            collector.stop()
        
        else:
            # å•æ‰‹æ¨¡å¼
            config = yaml.safe_load(open(config_path, 'r'))
            hand_name = args.mode.upper()
            hand_config = config.get(f'{args.mode}_hand', {})
            
            if not hand_config:
                print(f"âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° {args.mode}_hand é…ç½®")
                sys.exit(1)
            
            collector = HandCollector(hand_config, hand_name)
            collector.start()
            if not collector.wait_ready():
                print("âŒ åˆå§‹åŒ–å¤±è´¥")
                sys.exit(1)
            
            # é¢„çƒ­å’Œæ ¡å‡†
            sync_cfg = config.get('sync', {})
            warmup_time = sync_cfg.get('warmup_time', 1.0)
            calib_time = sync_cfg.get('calib_time', 0.5)
            collector.warmup_and_calibrate(warmup_time, calib_time)
            
            if args.visualize:
                visualize_hand(collector, hand_name)
            elif args.record:
                print("\næŒ‰å›è½¦é”®å¼€å§‹å½•åˆ¶...")
                input()
                collector.start_recording()
                print("å½•åˆ¶ä¸­... æŒ‰å›è½¦é”®åœæ­¢å½•åˆ¶")
                input()
                data = collector.stop_recording()
                if data:
                    print(f"\nå½•åˆ¶å®Œæˆ: {len(data)} å¸§")
                    # å•æ‰‹æ•°æ®å¯ä»¥ä¿å­˜ä¸ºå•ç‹¬çš„HDF5æ–‡ä»¶
                    save_cfg = config.get('save', {})
                    output_dir = save_cfg.get('output_dir', './data')
                    jpeg_quality = save_cfg.get('jpeg_quality', 85)
                    # è¿™é‡Œå¯ä»¥æ·»åŠ å•æ‰‹ä¿å­˜å‡½æ•°ï¼Œæš‚æ—¶åªæ‰“å°
                    print(f"æ•°æ®å·²æ”¶é›†ï¼Œå¯æ‰©å±•ä¿å­˜åŠŸèƒ½")
            
            collector.stop()
        
    except KeyboardInterrupt:
        print("\nä¸­æ–­")
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"\né”™è¯¯: {e}")

