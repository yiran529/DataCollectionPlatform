#!/usr/bin/env python3
"""
åŒæ‰‹åŒæ­¥æ•°æ®æ”¶é›†å™¨

åŒæ—¶æ”¶é›†å·¦å³æ‰‹çš„æ•°æ®ï¼š
- å·¦æ‰‹ï¼šå•ç›®ç›¸æœº + åŒç›®ç›¸æœº + è§’åº¦ç¼–ç å™¨
- å³æ‰‹ï¼šå•ç›®ç›¸æœº + åŒç›®ç›¸æœº + è§’åº¦ç¼–ç å™¨

æ‰€æœ‰æ•°æ®ä¿è¯æ—¶é—´åŒæ­¥å¯¹é½
"""

import sys
import os
import cv2
import numpy as np
import time
import threading
import yaml
import json
import glob
from dataclasses import dataclass
from typing import Optional, List, Tuple, Union
from collections import deque

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥sync_data_collector
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from data_coll.sync_data_collector import CameraReader, EncoderReader, SensorFrame

try:
    import minimalmodbus
except ImportError:
    minimalmodbus = None

try:
    import h5py
    HAS_H5PY = True
except ImportError:
    HAS_H5PY = False

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False


from hand_collector import HandCollector, HandFrame, visualize_hand

@dataclass
class DualHandFrame:
    """åŒæ‰‹åŒæ­¥å¸§"""
    left: HandFrame
    right: HandFrame
    timestamp: float
    idx: int

class DualHandCollector:
    """åŒæ‰‹åŒæ­¥æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, config_path: str, *, enable_realtime_write: bool = True,
                 output_dir: Optional[str] = None, jpeg_quality: Optional[int] = None):
        self.config_path = config_path
        self.config = self._load_config()
        
        save_cfg = self.config.get('save', {})
        self.enable_realtime_write = enable_realtime_write
        self.output_dir = output_dir if output_dir is not None else save_cfg.get('output_dir', './data')
        self.jpeg_quality = jpeg_quality if jpeg_quality is not None else save_cfg.get('jpeg_quality', 85)
        
        self.left: Optional[HandCollector] = None
        self.right: Optional[HandCollector] = None
        
        self._ready = False
        self._running = False
        self._recording = False
    
    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®"""
        with open(self.config_path, 'r') as f:
            return yaml.safe_load(f)
    
    @property
    def is_ready(self) -> bool:
        return self._ready
    
    @property
    def is_recording(self) -> bool:
        return self._recording
    
    def start(self) -> bool:
        """å¯åŠ¨æ”¶é›†å™¨"""
        if self._running:
            return True
        
        self._running = True
        self._ready = False
        
        # åˆå§‹åŒ–å·¦å³æ‰‹æ”¶é›†å™¨
        left_cfg = self.config.get('left_hand', {})
        right_cfg = self.config.get('right_hand', {})
        
        self.left = HandCollector(
            left_cfg,
            "LEFT",
            enable_realtime_write=self.enable_realtime_write,
            output_dir=self.output_dir,
            jpeg_quality=self.jpeg_quality
        )
        self.right = HandCollector(
            right_cfg,
            "RIGHT",
            enable_realtime_write=self.enable_realtime_write,
            output_dir=self.output_dir,
            jpeg_quality=self.jpeg_quality
        )
        
        # å¯åŠ¨
        self.left.start()
        self.right.start()
        
        # ç­‰å¾…å°±ç»ª
        if not self.left.wait_ready() or not self.right.wait_ready():
            print("âŒ åˆå§‹åŒ–å¤±è´¥")
            return False
        
        # é¢„çƒ­å’Œæ ¡å‡†
        sync_cfg = self.config.get('sync', {})
        warmup_time = sync_cfg.get('warmup_time', 1.0)
        calib_time = sync_cfg.get('calib_time', 0.5)
        
        self.left.warmup_and_calibrate(warmup_time, calib_time)
        self.right.warmup_and_calibrate(warmup_time, calib_time)
        
        self._ready = True
        print("\nâœ… åŒæ‰‹æ”¶é›†å™¨å°±ç»ª")
        return True
    
    def wait_ready(self, timeout: float = 60.0) -> bool:
        """ç­‰å¾…å°±ç»ª"""
        start = time.time()
        while not self._ready and (time.time() - start) < timeout:
            time.sleep(0.1)
        return self._ready
    
    def start_recording(self) -> bool:
        """å¼€å§‹å½•åˆ¶"""
        if not self._ready or self._recording:
            return False
        
        self._recording = True
        self.left.start_recording()
        self.right.start_recording()
        
        print("ğŸ”´ å¼€å§‹å½•åˆ¶åŒæ‰‹æ•°æ®...")
        return True
    
    def stop_recording(self) -> Union[Tuple[Optional[str], Optional[str]], List[DualHandFrame]]:
        """åœæ­¢å½•åˆ¶å¹¶è¿”å›å¯¹é½çš„åŒæ‰‹æ•°æ®æˆ–æ–‡ä»¶è·¯å¾„"""
        if not self._recording:
            return (None, None) if self.enable_realtime_write else []
        
        self._recording = False
        
        # è·å–å·¦å³æ‰‹ç»“æœ
        left_result = self.left.stop_recording()
        right_result = self.right.stop_recording()
        
        if self.enable_realtime_write:
            left_path = left_result if isinstance(left_result, str) else None
            right_path = right_result if isinstance(right_result, str) else None
            if left_path and right_path:
                print(f"\nåŒæ‰‹å®æ—¶å†™å…¥å®Œæˆ")
                print(f"  å·¦æ‰‹æ–‡ä»¶: {left_path}")
                print(f"  å³æ‰‹æ–‡ä»¶: {right_path}")
            else:
                print("\nâš ï¸ å®æ—¶å†™å…¥ç»“æœç¼ºå¤±ï¼Œè¯·æ£€æŸ¥å·¦å³æ‰‹æ–‡ä»¶æ˜¯å¦ç”ŸæˆæˆåŠŸ")
            return (left_path, right_path)
        
        left_data = left_result if isinstance(left_result, list) else []
        right_data = right_result if isinstance(right_result, list) else []
        
        aligned = self._align_hands(left_data, right_data)
        
        print(f"\nåŒæ‰‹å¯¹é½å®Œæˆ: {len(aligned)} å¸§")
        print(f"  å·¦æ‰‹: {len(left_data)} å¸§")
        print(f"  å³æ‰‹: {len(right_data)} å¸§")
        
        return aligned
    
    def _align_hands(self, left_data: List[HandFrame], 
                    right_data: List[HandFrame],
                    max_time_diff_ms: float = 50.0) -> List[DualHandFrame]:
        """å¯¹é½å·¦å³æ‰‹æ•°æ®"""
        aligned = []
        
        # ä»¥å·¦æ‰‹æ•°æ®ä¸ºåŸºå‡†å¯¹é½
        for left_frame in left_data:
            target_ts = left_frame.timestamp
            
            # æ‰¾åˆ°æœ€æ¥è¿‘çš„å³æ‰‹å¸§
            best_right = None
            if right_data:
                best_right = min(right_data, key=lambda x: abs(x.timestamp - target_ts))
                if abs(best_right.timestamp - target_ts) * 1000 > max_time_diff_ms:
                    best_right = None
            
            if best_right:
                aligned.append(DualHandFrame(
                    left=left_frame,
                    right=best_right,
                    timestamp=target_ts,
                    idx=len(aligned) + 1
                ))
        
        return aligned
    
    def stop(self):
        """åœæ­¢"""
        self._recording = False
        self._running = False
        self._ready = False
        
        if self.left:
            self.left.stop()
        if self.right:
            self.right.stop()
        
        print("åŒæ‰‹æ”¶é›†å™¨å·²åœæ­¢")


def save_dual_hand_data(data: List[DualHandFrame], output_dir: str,
                        jpeg_quality: int = 85) -> str:
    """ä¿å­˜åŒæ‰‹æ•°æ®åˆ°HDF5ï¼ˆæµå¼å†™å…¥ä¼˜åŒ–å†…å­˜ï¼‰"""
    if not data:
        print("âŒ æ— æ•°æ®")
        return None
    
    if not HAS_H5PY:
        print("âŒ h5py æœªå®‰è£…ï¼Œæ— æ³•ä¿å­˜æ•°æ®")
        return None
    
    from datetime import datetime
    import h5py
    
    os.makedirs(output_dir, exist_ok=True)
    prefix = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_dual_hand_data.h5"
    filepath = os.path.join(output_dir, filename)
    
    n_frames = len(data)
    print(f"\nä¿å­˜åŒæ‰‹æ•°æ®: {filepath}")
    print(f"  å¸§æ•°: {n_frames}")
    
    start_time = time.time()
    
    # æµå¼å†™å…¥HDF5ï¼ˆé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜ï¼‰
    encode_params = [cv2.IMWRITE_JPEG_QUALITY, jpeg_quality]
    
    print("  å†™å…¥HDF5ï¼ˆæµå¼ï¼‰...")
    write_start = time.time()
    
    with h5py.File(filepath, 'w', libver='latest') as f:
        # å…ƒæ•°æ®
        f.attrs['n_frames'] = n_frames
        f.attrs['left_stereo_shape'] = data[0].left.stereo.shape
        f.attrs['left_mono_shape'] = data[0].left.mono.shape
        f.attrs['right_stereo_shape'] = data[0].right.stereo.shape
        f.attrs['right_mono_shape'] = data[0].right.mono.shape
        f.attrs['jpeg_quality'] = jpeg_quality
        f.attrs['created_at'] = datetime.now().isoformat()
        
        # åˆ›å»ºæ•°æ®é›†ï¼ˆä½¿ç”¨å¯å˜é•¿åº¦æ•°æ®ç±»å‹ï¼‰
        dt = h5py.special_dtype(vlen=np.uint8)
        
        # åˆ›å»ºæ•°æ®é›†ï¼ˆé¢„å…ˆåˆ†é…ç©ºé—´ï¼‰
        left_stereo_ds = f.create_dataset('left_stereo_jpeg', (n_frames,), dtype=dt)
        left_mono_ds = f.create_dataset('left_mono_jpeg', (n_frames,), dtype=dt)
        right_stereo_ds = f.create_dataset('right_stereo_jpeg', (n_frames,), dtype=dt)
        right_mono_ds = f.create_dataset('right_mono_jpeg', (n_frames,), dtype=dt)
        
        left_angles = np.zeros(n_frames, dtype=np.float32)
        left_timestamps = np.zeros(n_frames, dtype=np.float64)
        right_angles = np.zeros(n_frames, dtype=np.float32)
        right_timestamps = np.zeros(n_frames, dtype=np.float64)
        sync_timestamps = np.zeros(n_frames, dtype=np.float64)
        
        # åˆ†æ‰¹å¤„ç†å’Œå†™å…¥ï¼ˆæ¯æ‰¹100å¸§ï¼‰
        batch_size = 100
        for i in range(0, n_frames, batch_size):
            batch_end = min(i + batch_size, n_frames)
            batch_data = data[i:batch_end]
            
            for j, frame in enumerate(batch_data):
                idx = i + j
                
                # å‹ç¼©å›¾åƒï¼ˆç«‹å³å†™å…¥ï¼Œä¸ä¿å­˜åˆ°åˆ—è¡¨ï¼‰
                success_ls, ls = cv2.imencode('.jpg', frame.left.stereo, encode_params)
                success_lm, lm = cv2.imencode('.jpg', frame.left.mono, encode_params)
                success_rs, rs = cv2.imencode('.jpg', frame.right.stereo, encode_params)
                success_rm, rm = cv2.imencode('.jpg', frame.right.mono, encode_params)
                
                if not (success_ls and success_lm and success_rs and success_rm):
                    print(f"\nâš ï¸ è­¦å‘Š: ç¬¬ {idx} å¸§å›¾åƒå‹ç¼©å¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # å¯¹äºå¯å˜é•¿åº¦æ•°æ®ç±»å‹ï¼Œç›´æ¥ä¼ é€’numpyæ•°ç»„ï¼ˆh5pyä¼šè‡ªåŠ¨å¤„ç†ï¼‰
                left_stereo_ds[idx] = ls
                left_mono_ds[idx] = lm
                right_stereo_ds[idx] = rs
                right_mono_ds[idx] = rm
                
                left_angles[idx] = frame.left.angle
                left_timestamps[idx] = frame.left.timestamp
                right_angles[idx] = frame.right.angle
                right_timestamps[idx] = frame.right.timestamp
                sync_timestamps[idx] = frame.timestamp
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = (batch_end / n_frames) * 100
            print(f"  è¿›åº¦: {batch_end}/{n_frames} ({progress:.1f}%)", end='\r')
        
        print()  # æ¢è¡Œ
        
        # å†™å…¥è§’åº¦å’Œæ—¶é—´æˆ³æ•°æ®
        f.create_dataset('left_angles', data=left_angles, dtype=np.float32)
        f.create_dataset('left_timestamps', data=left_timestamps, dtype=np.float64)
        f.create_dataset('right_angles', data=right_angles, dtype=np.float32)
        f.create_dataset('right_timestamps', data=right_timestamps, dtype=np.float64)
        f.create_dataset('sync_timestamps', data=sync_timestamps, dtype=np.float64)
    
    write_time = time.time() - write_start
    total_time = time.time() - start_time
    
    file_size = os.path.getsize(filepath) / (1024 * 1024)
    
    print(f"  å†™å…¥è€—æ—¶: {write_time:.2f}s")
    print(f"  æ€»è€—æ—¶: {total_time:.2f}s")
    print(f"  æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
    print(f"âœ… ä¿å­˜å®Œæˆ: {filepath}")
    
    return filepath


def merge_dual_hand_files(left_path: Optional[str], right_path: Optional[str],
                          output_dir: Optional[str] = None,
                          max_time_diff_ms: float = 50.0) -> Optional[str]:
    """ç¦»çº¿å¯¹é½å·¦å³æ‰‹å®æ—¶å†™å…¥æ–‡ä»¶å¹¶åˆå¹¶ä¸ºä¸€ä¸ªåŒæ‰‹æ•°æ®æ–‡ä»¶"""
    if not HAS_H5PY:
        print("âŒ h5py æœªå®‰è£…ï¼Œæ— æ³•åˆå¹¶åŒæ‰‹æ•°æ®")
        return None
    if not left_path or not right_path:
        print("âŒ ç¼ºå°‘å·¦å³æ‰‹æ–‡ä»¶è·¯å¾„ï¼Œæ— æ³•åˆå¹¶")
        return None
    if not os.path.exists(left_path):
        print(f"âŒ å·¦æ‰‹æ–‡ä»¶ä¸å­˜åœ¨: {left_path}")
        return None
    if not os.path.exists(right_path):
        print(f"âŒ å³æ‰‹æ–‡ä»¶ä¸å­˜åœ¨: {right_path}")
        return None

    output_dir = output_dir or os.path.dirname(left_path)
    os.makedirs(output_dir, exist_ok=True)

    try:
        from datetime import datetime
        max_diff_s = max_time_diff_ms / 1000.0
        with h5py.File(left_path, 'r') as left_f, h5py.File(right_path, 'r') as right_f:
            left_ts = np.asarray(left_f['timestamps'], dtype=np.float64)
            right_ts = np.asarray(right_f['timestamps'], dtype=np.float64)
            n_left = left_ts.shape[0]
            n_right = right_ts.shape[0]
            if n_left == 0 or n_right == 0:
                print("âŒ å·¦å³æ‰‹æ–‡ä»¶ä¸­å­˜åœ¨ç©ºæ•°æ®é›†ï¼Œæ— æ³•åˆå¹¶")
                return None

            pairs: List[Tuple[int, int]] = []
            r_idx = 0
            while r_idx < n_right and right_ts[r_idx] < left_ts[0] - max_diff_s:
                r_idx += 1
            for l_idx, l_ts in enumerate(left_ts):
                while r_idx < n_right and right_ts[r_idx] < l_ts - max_diff_s:
                    r_idx += 1
                if r_idx >= n_right:
                    break
                best_idx = r_idx
                while (best_idx + 1 < n_right and
                       abs(right_ts[best_idx + 1] - l_ts) <= abs(right_ts[best_idx] - l_ts)):
                    best_idx += 1
                if abs(right_ts[best_idx] - l_ts) <= max_diff_s:
                    pairs.append((l_idx, best_idx))
                    if best_idx + 1 < n_right:
                        r_idx = best_idx + 1
                    else:
                        r_idx = n_right

            if not pairs:
                print("âŒ æœªæ‰¾åˆ°å¯å¯¹é½çš„å·¦å³æ‰‹å¸§ï¼Œè¯·æ£€æŸ¥æ•°æ®æ—¶é—´æˆ³")
                return None

            n_aligned = len(pairs)
            prefix = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{prefix}_dual_hand_data.h5"
            merged_path = os.path.join(output_dir, filename)

            with h5py.File(merged_path, 'w', libver='latest') as out_f:
                out_f.attrs['n_frames'] = n_aligned
                out_f.attrs['jpeg_quality'] = left_f.attrs.get('jpeg_quality', 85)
                out_f.attrs['created_at'] = datetime.now().isoformat()
                out_f.attrs['left_source'] = os.path.basename(left_path)
                out_f.attrs['right_source'] = os.path.basename(right_path)
                out_f.attrs['merge_mode'] = 'offline_align'
                out_f.attrs['max_time_diff_ms'] = max_time_diff_ms
                if 'hand' in left_f.attrs:
                    out_f.attrs['left_hand'] = left_f.attrs['hand']
                if 'hand' in right_f.attrs:
                    out_f.attrs['right_hand'] = right_f.attrs['hand']
                if 'stereo_shape' in left_f.attrs:
                    out_f.attrs['left_stereo_shape'] = left_f.attrs['stereo_shape']
                if 'mono_shape' in left_f.attrs:
                    out_f.attrs['left_mono_shape'] = left_f.attrs['mono_shape']
                if 'stereo_shape' in right_f.attrs:
                    out_f.attrs['right_stereo_shape'] = right_f.attrs['stereo_shape']
                if 'mono_shape' in right_f.attrs:
                    out_f.attrs['right_mono_shape'] = right_f.attrs['mono_shape']

                dt = h5py.special_dtype(vlen=np.uint8)
                left_stereo_ds = out_f.create_dataset('left_stereo_jpeg', (n_aligned,), dtype=dt)
                left_mono_ds = out_f.create_dataset('left_mono_jpeg', (n_aligned,), dtype=dt)
                right_stereo_ds = out_f.create_dataset('right_stereo_jpeg', (n_aligned,), dtype=dt)
                right_mono_ds = out_f.create_dataset('right_mono_jpeg', (n_aligned,), dtype=dt)

                left_angles = np.zeros(n_aligned, dtype=np.float32)
                left_timestamps = np.zeros(n_aligned, dtype=np.float64)
                left_stereo_ts = np.zeros(n_aligned, dtype=np.float64)
                left_mono_ts = np.zeros(n_aligned, dtype=np.float64)
                left_encoder_ts = np.zeros(n_aligned, dtype=np.float64)

                right_angles = np.zeros(n_aligned, dtype=np.float32)
                right_timestamps = np.zeros(n_aligned, dtype=np.float64)
                right_stereo_ts = np.zeros(n_aligned, dtype=np.float64)
                right_mono_ts = np.zeros(n_aligned, dtype=np.float64)
                right_encoder_ts = np.zeros(n_aligned, dtype=np.float64)

                sync_timestamps = np.zeros(n_aligned, dtype=np.float64)

                for idx, (l_idx, r_idx_pair) in enumerate(pairs):
                    left_stereo_ds[idx] = left_f['stereo_jpeg'][l_idx]
                    left_mono_ds[idx] = left_f['mono_jpeg'][l_idx]
                    right_stereo_ds[idx] = right_f['stereo_jpeg'][r_idx_pair]
                    right_mono_ds[idx] = right_f['mono_jpeg'][r_idx_pair]

                    left_angles[idx] = float(left_f['angles'][l_idx])
                    left_timestamps[idx] = float(left_f['timestamps'][l_idx])
                    left_stereo_ts[idx] = float(left_f['stereo_timestamps'][l_idx])
                    left_mono_ts[idx] = float(left_f['mono_timestamps'][l_idx])
                    left_encoder_ts[idx] = float(left_f['encoder_timestamps'][l_idx])

                    right_angles[idx] = float(right_f['angles'][r_idx_pair])
                    right_timestamps[idx] = float(right_f['timestamps'][r_idx_pair])
                    right_stereo_ts[idx] = float(right_f['stereo_timestamps'][r_idx_pair])
                    right_mono_ts[idx] = float(right_f['mono_timestamps'][r_idx_pair])
                    right_encoder_ts[idx] = float(right_f['encoder_timestamps'][r_idx_pair])

                    sync_timestamps[idx] = (left_timestamps[idx] + right_timestamps[idx]) / 2.0

                out_f.create_dataset('left_angles', data=left_angles, dtype=np.float32)
                out_f.create_dataset('left_timestamps', data=left_timestamps, dtype=np.float64)
                out_f.create_dataset('left_stereo_timestamps', data=left_stereo_ts, dtype=np.float64)
                out_f.create_dataset('left_mono_timestamps', data=left_mono_ts, dtype=np.float64)
                out_f.create_dataset('left_encoder_timestamps', data=left_encoder_ts, dtype=np.float64)

                out_f.create_dataset('right_angles', data=right_angles, dtype=np.float32)
                out_f.create_dataset('right_timestamps', data=right_timestamps, dtype=np.float64)
                out_f.create_dataset('right_stereo_timestamps', data=right_stereo_ts, dtype=np.float64)
                out_f.create_dataset('right_mono_timestamps', data=right_mono_ts, dtype=np.float64)
                out_f.create_dataset('right_encoder_timestamps', data=right_encoder_ts, dtype=np.float64)

                out_f.create_dataset('sync_timestamps', data=sync_timestamps, dtype=np.float64)

        os.remove(left_path)
        os.remove(right_path)

        print(f"âœ… åŒæ‰‹æ•°æ®åˆå¹¶å®Œæˆ: {merged_path}")
        print(f"  å¯¹é½å¸§æ•°: {n_aligned}")
        return merged_path
    except Exception as exc:
        print(f"âŒ åˆå¹¶åŒæ‰‹æ•°æ®å¤±è´¥: {exc}")
        return None


def visualize_dual_hand(collector: DualHandCollector):
    """å¯è§†åŒ–åŒæ‰‹æ•°æ®"""
    print("\nåŒæ‰‹å¯è§†åŒ–ï¼ˆæŒ‰ 'q' é€€å‡ºï¼‰...")
    
    window_name = "Dual Hand - Press 'q' to quit"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    
    left_angle_history = []
    right_angle_history = []
    max_history = 100
    
    try:
        while True:
            left_frame = collector.left.get_current_frame() if collector.left else None
            right_frame = collector.right.get_current_frame() if collector.right else None
            
            if left_frame is None and right_frame is None:
                time.sleep(0.01)
                continue
            
            displays = []
            
            # å¤„ç†å·¦æ‰‹
            if left_frame:
                stereo_img = left_frame.stereo.copy()
                mono_img = left_frame.mono.copy()
                angle = left_frame.angle
                
                left_angle_history.append(angle)
                if len(left_angle_history) > max_history:
                    left_angle_history.pop(0)
                
                # åˆ†å‰²åŒç›®
                stereo_h, stereo_w = stereo_img.shape[:2]
                if stereo_w > stereo_h:
                    left_stereo = stereo_img[:, :stereo_w//2]
                    right_stereo = stereo_img[:, stereo_w//2:]
                else:
                    left_stereo = stereo_img[:stereo_h//2, :]
                    right_stereo = stereo_img[stereo_h//2:, :]
                
                # ä¿æŒåŸå§‹å°ºå¯¸ï¼Œä¸è¿›è¡Œresize
                mono_display = mono_img.copy()
                left_display = left_stereo.copy()
                right_display = right_stereo.copy()
                
                # è§’åº¦æ˜¾ç¤ºï¼ˆé«˜åº¦ä¸mono_displayåŒ¹é…ï¼‰
                angle_img = np.zeros((mono_display.shape[0], 300, 3), dtype=np.uint8)
                angle_img_h = angle_img.shape[0]
                angle_img_w = angle_img.shape[1]
                cv2.putText(angle_img, f"L: {angle:.2f}Â°", (10, 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                if len(left_angle_history) > 1:
                    points = []
                    for i, a in enumerate(left_angle_history):
                        x = int((i / max(len(left_angle_history) - 1, 1)) * (angle_img_w - 20) + 10)
                        y = int(angle_img_h - 20 - (a + 180) / 360 * (angle_img_h - 40))
                        points.append((x, y))
                    for i in range(len(points) - 1):
                        cv2.line(angle_img, points[i], points[i+1], (0, 255, 255), 2)
                
                left_row = np.hstack([left_display, right_display])
                left_bottom = np.hstack([mono_display, angle_img])
                if left_row.shape[1] != left_bottom.shape[1]:
                    target_w = max(left_row.shape[1], left_bottom.shape[1])
                    if left_row.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((left_row.shape[0], target_w - left_row.shape[1], 3), dtype=np.uint8)
                        left_row = np.hstack([left_row, padding])
                    if left_bottom.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((left_bottom.shape[0], target_w - left_bottom.shape[1], 3), dtype=np.uint8)
                        left_bottom = np.hstack([left_bottom, padding])
                
                left_display_full = np.vstack([left_row, left_bottom])
                displays.append(left_display_full)
            
            # å¤„ç†å³æ‰‹
            if right_frame:
                stereo_img = right_frame.stereo.copy()
                mono_img = right_frame.mono.copy()
                angle = right_frame.angle
                
                right_angle_history.append(angle)
                if len(right_angle_history) > max_history:
                    right_angle_history.pop(0)
                
                # åˆ†å‰²åŒç›®
                stereo_h, stereo_w = stereo_img.shape[:2]
                if stereo_w > stereo_h:
                    left_stereo = stereo_img[:, :stereo_w//2]
                    right_stereo = stereo_img[:, stereo_w//2:]
                else:
                    left_stereo = stereo_img[:stereo_h//2, :]
                    right_stereo = stereo_img[stereo_h//2:, :]
                
                # ä¿æŒåŸå§‹å°ºå¯¸ï¼Œä¸è¿›è¡Œresize
                mono_display = mono_img.copy()
                left_display = left_stereo.copy()
                right_display = right_stereo.copy()
                
                # è§’åº¦æ˜¾ç¤ºï¼ˆé«˜åº¦ä¸mono_displayåŒ¹é…ï¼‰
                angle_img = np.zeros((mono_display.shape[0], 300, 3), dtype=np.uint8)
                angle_img_h = angle_img.shape[0]
                angle_img_w = angle_img.shape[1]
                cv2.putText(angle_img, f"R: {angle:.2f}Â°", (10, 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                if len(right_angle_history) > 1:
                    points = []
                    for i, a in enumerate(right_angle_history):
                        x = int((i / max(len(right_angle_history) - 1, 1)) * (angle_img_w - 20) + 10)
                        y = int(angle_img_h - 20 - (a + 180) / 360 * (angle_img_h - 40))
                        points.append((x, y))
                    for i in range(len(points) - 1):
                        cv2.line(angle_img, points[i], points[i+1], (0, 255, 255), 2)
                
                right_row = np.hstack([left_display, right_display])
                right_bottom = np.hstack([mono_display, angle_img])
                if right_row.shape[1] != right_bottom.shape[1]:
                    target_w = max(right_row.shape[1], right_bottom.shape[1])
                    if right_row.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((right_row.shape[0], target_w - right_row.shape[1], 3), dtype=np.uint8)
                        right_row = np.hstack([right_row, padding])
                    if right_bottom.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((right_bottom.shape[0], target_w - right_bottom.shape[1], 3), dtype=np.uint8)
                        right_bottom = np.hstack([right_bottom, padding])
                
                right_display_full = np.vstack([right_row, right_bottom])
                displays.append(right_display_full)
            
            if displays:
                # ç»„åˆæ˜¾ç¤º
                if len(displays) == 2:
                    # åŒæ‰‹ï¼šä¸Šä¸‹æ’åˆ—
                    final_display = np.vstack(displays)
                else:
                    final_display = displays[0]
                
                # æ·»åŠ æ ‡é¢˜
                title_height = 30
                title_img = np.zeros((title_height, final_display.shape[1], 3), dtype=np.uint8)
                title_text = "Dual Hand Visualization - Press 'q' to quit"
                cv2.putText(title_img, title_text, (10, 20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
                final_display = np.vstack([title_img, final_display])
                
                cv2.imshow(window_name, final_display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            
            time.sleep(0.01)
    
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyWindow(window_name)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="åŒæ‰‹æ•°æ®æ”¶é›†å™¨")
    parser.add_argument("--config", "-c", type=str, default="config.yaml",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--mode", "-m", type=str, choices=['left', 'right', 'both'],
                       default='both', help="æµ‹è¯•æ¨¡å¼: left(å·¦æ‰‹), right(å³æ‰‹), both(åŒæ‰‹)")
    parser.add_argument("--visualize", "-v", action="store_true",
                       help="å¯ç”¨å¯è§†åŒ–æ¨¡å¼")
    parser.add_argument("--record", "-r", action="store_true",
                       help="å½•åˆ¶æ¨¡å¼ï¼ˆä¸å¯è§†åŒ–æ¨¡å¼äº’æ–¥ï¼‰")
    parser.add_argument("--realtime-write", dest="realtime_write", action="store_true",
                       help="å¯ç”¨å®æ—¶å†™å…¥æ¨¡å¼ï¼ˆå½•åˆ¶æ—¶ç›´æ¥å†™å…¥ç£ç›˜ï¼Œé»˜è®¤å¼€å¯ï¼‰")
    parser.add_argument("--no-realtime-write", dest="realtime_write", action="store_false",
                       help="ç¦ç”¨å®æ—¶å†™å…¥æ¨¡å¼ï¼ˆæ”¹ä¸ºå†…å­˜ç¼“å­˜åç¦»çº¿ä¿å­˜ï¼‰")
    parser.set_defaults(realtime_write=True)
    args = parser.parse_args()
    
    config_path = args.config
    if not os.path.isabs(config_path):
        config_path = os.path.join(os.path.dirname(__file__), config_path)
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å¼ï¼Œé»˜è®¤ä½¿ç”¨å¯è§†åŒ–
    if not args.visualize and not args.record:
        args.visualize = True
    
    try:
        if args.mode == 'both':
            # åŒæ‰‹æ¨¡å¼
            collector = DualHandCollector(
                config_path,
                enable_realtime_write=args.realtime_write
            )
            collector.start()
            if not collector.wait_ready():
                print("âŒ åˆå§‹åŒ–å¤±è´¥")
                sys.exit(1)
            
            if args.visualize:
                visualize_dual_hand(collector)
            elif args.record:
                print("\næŒ‰å›è½¦é”®å¼€å§‹å½•åˆ¶...")
                input()
                collector.start_recording()
                print("å½•åˆ¶ä¸­... æŒ‰å›è½¦é”®åœæ­¢å½•åˆ¶")
                input()
                result = collector.stop_recording()
                save_cfg = collector.config.get('save', {})
                output_dir = save_cfg.get('output_dir', './data')
                jpeg_quality = save_cfg.get('jpeg_quality', 85)
                if args.realtime_write:
                    left_path, right_path = result if isinstance(result, tuple) else (None, None)
                    merged_path = merge_dual_hand_files(left_path, right_path, collector.output_dir)
                    if merged_path:
                        print(f"\nâœ… åŒæ‰‹æ•°æ®å·²åˆå¹¶ä¿å­˜åˆ°: {merged_path}")
                else:
                    if result:
                        save_dual_hand_data(result, output_dir, jpeg_quality)
            collector.stop()
        
        else:
            # å•æ‰‹æ¨¡å¼
            config = yaml.safe_load(open(config_path, 'r'))
            hand_name = args.mode.upper()
            hand_config = config.get(f'{args.mode}_hand', {})
            
            if not hand_config:
                print(f"âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° {args.mode}_hand é…ç½®")
                sys.exit(1)
            
            save_cfg = config.get('save', {})
            output_dir = save_cfg.get('output_dir', './data')
            jpeg_quality = save_cfg.get('jpeg_quality', 85)
            collector = HandCollector(
                hand_config,
                hand_name,
                enable_realtime_write=args.realtime_write,
                output_dir=output_dir,
                jpeg_quality=jpeg_quality
            )
            collector.start()
            if not collector.wait_ready():
                print("âŒ åˆå§‹åŒ–å¤±è´¥")
                sys.exit(1)
            
            # é¢„çƒ­å’Œæ ¡å‡†
            sync_cfg = config.get('sync', {})
            warmup_time = sync_cfg.get('warmup_time', 1.0)
            calib_time = sync_cfg.get('calib_time', 0.5)
            collector.warmup_and_calibrate(warmup_time, calib_time)
            
            if args.visualize:
                visualize_hand(collector, hand_name)
            elif args.record:
                print("\næŒ‰å›è½¦é”®å¼€å§‹å½•åˆ¶...")
                input()
                collector.start_recording()
                print("å½•åˆ¶ä¸­... æŒ‰å›è½¦é”®åœæ­¢å½•åˆ¶")
                input()
                data = collector.stop_recording()
                if args.realtime_write:
                    if isinstance(data, str) and data:
                        print(f"\n[{hand_name}] âœ… æ•°æ®å·²å®æ—¶ä¿å­˜åˆ°: {data}")
                else:
                    if isinstance(data, list) and data:
                        print(f"\nå½•åˆ¶å®Œæˆ: {len(data)} å¸§")
                        print("æ•°æ®å·²æ”¶é›†ï¼Œå¯æ‰©å±•ä¿å­˜åŠŸèƒ½")
            
            collector.stop()
        
    except KeyboardInterrupt:
        print("\nä¸­æ–­")
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"\né”™è¯¯: {e}")

