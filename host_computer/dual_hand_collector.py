#!/usr/bin/env python3
"""
åŒæ‰‹åŒæ­¥æ•°æ®æ”¶é›†å™¨

åŒæ—¶æ”¶é›†å·¦å³æ‰‹çš„æ•°æ®ï¼š
- å·¦æ‰‹ï¼šå•ç›®ç›¸æœº + åŒç›®ç›¸æœº + è§’åº¦ç¼–ç å™¨
- å³æ‰‹ï¼šå•ç›®ç›¸æœº + åŒç›®ç›¸æœº + è§’åº¦ç¼–ç å™¨

æ‰€æœ‰æ•°æ®ä¿è¯æ—¶é—´åŒæ­¥å¯¹é½
"""

import sys
import os
import cv2
import numpy as np
import time
import threading
import yaml
import json
import glob
from dataclasses import dataclass
from typing import Optional, List, Dict
from collections import deque

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥sync_data_collector
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from data_coll.sync_data_collector import CameraReader, EncoderReader, SensorFrame

try:
    import minimalmodbus
except ImportError:
    minimalmodbus = None

try:
    import h5py
    HAS_H5PY = True
except ImportError:
    HAS_H5PY = False

try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False


from hand_collector import HandFrame, HandCollector, visualize_hand


@dataclass
class DualHandFrame:
    """åŒæ‰‹åŒæ­¥å¸§"""
    left: HandFrame
    right: HandFrame
    timestamp: float
    idx: int



class DualHandCollector:
    """åŒæ‰‹åŒæ­¥æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, config_path: str):
        self.config_path = config_path
        self.config = self._load_config()
        
        self.left: Optional[HandCollector] = None
        self.right: Optional[HandCollector] = None
        
        self._ready = False
        self._running = False
        self._recording = False
    
    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®"""
        with open(self.config_path, 'r') as f:
            return yaml.safe_load(f)
    
    @property
    def is_ready(self) -> bool:
        return self._ready
    
    @property
    def is_recording(self) -> bool:
        return self._recording
    
    def start(self) -> bool:
        """å¯åŠ¨æ”¶é›†å™¨"""
        if self._running:
            return True
        
        self._running = True
        self._ready = False
        
        # åˆå§‹åŒ–å·¦å³æ‰‹æ”¶é›†å™¨
        left_cfg = self.config.get('left_hand', {})
        right_cfg = self.config.get('right_hand', {})
        
        self.left = HandCollector(left_cfg, "LEFT")
        self.right = HandCollector(right_cfg, "RIGHT")
        
        # å¯åŠ¨
        self.left.start()
        self.right.start()
        
        # ç­‰å¾…å°±ç»ª
        if not self.left.wait_ready() or not self.right.wait_ready():
            print("âŒ åˆå§‹åŒ–å¤±è´¥")
            return False
        
        # é¢„çƒ­å’Œæ ¡å‡†
        sync_cfg = self.config.get('sync', {})
        warmup_time = sync_cfg.get('warmup_time', 1.0)
        calib_time = sync_cfg.get('calib_time', 0.5)
        
        self.left.warmup_and_calibrate(warmup_time, calib_time)
        self.right.warmup_and_calibrate(warmup_time, calib_time)
        
        self._ready = True
        print("\nâœ… åŒæ‰‹æ”¶é›†å™¨å°±ç»ª")
        return True
    
    def wait_ready(self, timeout: float = 60.0) -> bool:
        """ç­‰å¾…å°±ç»ª"""
        start = time.time()
        while not self._ready and (time.time() - start) < timeout:
            time.sleep(0.1)
        return self._ready
    
    def start_recording(self) -> bool:
        """å¼€å§‹å½•åˆ¶"""
        if not self._ready or self._recording:
            return False
        
        self._recording = True
        self.left.start_recording()
        self.right.start_recording()
        
        print("ðŸ”´ å¼€å§‹å½•åˆ¶åŒæ‰‹æ•°æ®...")
        return True
    
    def stop_recording(self) -> List[DualHandFrame]:
        """åœæ­¢å½•åˆ¶å¹¶è¿”å›žå¯¹é½çš„åŒæ‰‹æ•°æ®"""
        if not self._recording:
            return []
        
        self._recording = False
        
        # èŽ·å–å·¦å³æ‰‹æ•°æ®
        left_data = self.left.stop_recording()
        right_data = self.right.stop_recording()
        
        # å¯¹é½åŒæ‰‹æ•°æ®
        aligned = self._align_hands(left_data, right_data)
        
        print(f"\nåŒæ‰‹å¯¹é½å®Œæˆ: {len(aligned)} å¸§")
        print(f"  å·¦æ‰‹: {len(left_data)} å¸§")
        print(f"  å³æ‰‹: {len(right_data)} å¸§")
        
        return aligned
    
    def _align_hands(self, left_data: List[HandFrame], 
                    right_data: List[HandFrame],
                    max_time_diff_ms: float = 50.0) -> List[DualHandFrame]:
        """å¯¹é½å·¦å³æ‰‹æ•°æ®"""
        aligned = []
        
        # ä»¥å·¦æ‰‹æ•°æ®ä¸ºåŸºå‡†å¯¹é½
        for left_frame in left_data:
            target_ts = left_frame.timestamp
            
            # æ‰¾åˆ°æœ€æŽ¥è¿‘çš„å³æ‰‹å¸§
            best_right = None
            if right_data:
                best_right = min(right_data, key=lambda x: abs(x.timestamp - target_ts))
                if abs(best_right.timestamp - target_ts) * 1000 > max_time_diff_ms:
                    best_right = None
            
            if best_right:
                aligned.append(DualHandFrame(
                    left=left_frame,
                    right=best_right,
                    timestamp=target_ts,
                    idx=len(aligned) + 1
                ))
        
        return aligned
    
    def stop(self):
        """åœæ­¢"""
        self._recording = False
        self._running = False
        self._ready = False
        
        if self.left:
            self.left.stop()
        if self.right:
            self.right.stop()
        
        print("åŒæ‰‹æ”¶é›†å™¨å·²åœæ­¢")


def save_dual_hand_data(data: List[DualHandFrame], output_dir: str,
                        jpeg_quality: int = 85) -> str:
    """ä¿å­˜åŒæ‰‹æ•°æ®åˆ°HDF5ï¼ˆæµå¼å†™å…¥ä¼˜åŒ–å†…å­˜ï¼‰"""
    if not data:
        print("âŒ æ— æ•°æ®")
        return None
    
    if not HAS_H5PY:
        print("âŒ h5py æœªå®‰è£…ï¼Œæ— æ³•ä¿å­˜æ•°æ®")
        return None
    
    from datetime import datetime
    import h5py
    
    os.makedirs(output_dir, exist_ok=True)
    prefix = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_dual_hand_data.h5"
    filepath = os.path.join(output_dir, filename)
    
    n_frames = len(data)
    print(f"\nä¿å­˜åŒæ‰‹æ•°æ®: {filepath}")
    print(f"  å¸§æ•°: {n_frames}")
    
    start_time = time.time()
    
    # æµå¼å†™å…¥HDF5ï¼ˆé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜ï¼‰
    encode_params = [cv2.IMWRITE_JPEG_QUALITY, jpeg_quality]
    
    print("  å†™å…¥HDF5ï¼ˆæµå¼ï¼‰...")
    write_start = time.time()
    
    with h5py.File(filepath, 'w', libver='latest') as f:
        # å…ƒæ•°æ®
        f.attrs['n_frames'] = n_frames
        f.attrs['left_stereo_shape'] = data[0].left.stereo.shape
        f.attrs['left_mono_shape'] = data[0].left.mono.shape
        f.attrs['right_stereo_shape'] = data[0].right.stereo.shape
        f.attrs['right_mono_shape'] = data[0].right.mono.shape
        f.attrs['jpeg_quality'] = jpeg_quality
        f.attrs['created_at'] = datetime.now().isoformat()
        
        # åˆ›å»ºæ•°æ®é›†ï¼ˆä½¿ç”¨å¯å˜é•¿åº¦æ•°æ®ç±»åž‹ï¼‰
        dt = h5py.special_dtype(vlen=np.uint8)
        
        # åˆ›å»ºæ•°æ®é›†ï¼ˆé¢„å…ˆåˆ†é…ç©ºé—´ï¼‰
        left_stereo_ds = f.create_dataset('left_stereo_jpeg', (n_frames,), dtype=dt)
        left_mono_ds = f.create_dataset('left_mono_jpeg', (n_frames,), dtype=dt)
        right_stereo_ds = f.create_dataset('right_stereo_jpeg', (n_frames,), dtype=dt)
        right_mono_ds = f.create_dataset('right_mono_jpeg', (n_frames,), dtype=dt)
        
        left_angles = np.zeros(n_frames, dtype=np.float32)
        left_timestamps = np.zeros(n_frames, dtype=np.float64)
        right_angles = np.zeros(n_frames, dtype=np.float32)
        right_timestamps = np.zeros(n_frames, dtype=np.float64)
        sync_timestamps = np.zeros(n_frames, dtype=np.float64)
        
        # åˆ†æ‰¹å¤„ç†å’Œå†™å…¥ï¼ˆæ¯æ‰¹100å¸§ï¼‰
        batch_size = 100
        for i in range(0, n_frames, batch_size):
            batch_end = min(i + batch_size, n_frames)
            batch_data = data[i:batch_end]
            
            for j, frame in enumerate(batch_data):
                idx = i + j
                
                # åŽ‹ç¼©å›¾åƒï¼ˆç«‹å³å†™å…¥ï¼Œä¸ä¿å­˜åˆ°åˆ—è¡¨ï¼‰
                success_ls, ls = cv2.imencode('.jpg', frame.left.stereo, encode_params)
                success_lm, lm = cv2.imencode('.jpg', frame.left.mono, encode_params)
                success_rs, rs = cv2.imencode('.jpg', frame.right.stereo, encode_params)
                success_rm, rm = cv2.imencode('.jpg', frame.right.mono, encode_params)
                
                if not (success_ls and success_lm and success_rs and success_rm):
                    print(f"\nâš ï¸ è­¦å‘Š: ç¬¬ {idx} å¸§å›¾åƒåŽ‹ç¼©å¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # å¯¹äºŽå¯å˜é•¿åº¦æ•°æ®ç±»åž‹ï¼Œç›´æŽ¥ä¼ é€’numpyæ•°ç»„ï¼ˆh5pyä¼šè‡ªåŠ¨å¤„ç†ï¼‰
                left_stereo_ds[idx] = ls
                left_mono_ds[idx] = lm
                right_stereo_ds[idx] = rs
                right_mono_ds[idx] = rm
                
                left_angles[idx] = frame.left.angle
                left_timestamps[idx] = frame.left.timestamp
                right_angles[idx] = frame.right.angle
                right_timestamps[idx] = frame.right.timestamp
                sync_timestamps[idx] = frame.timestamp
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = (batch_end / n_frames) * 100
            print(f"  è¿›åº¦: {batch_end}/{n_frames} ({progress:.1f}%)", end='\r')
        
        print()  # æ¢è¡Œ
        
        # å†™å…¥è§’åº¦å’Œæ—¶é—´æˆ³æ•°æ®
        f.create_dataset('left_angles', data=left_angles, dtype=np.float32)
        f.create_dataset('left_timestamps', data=left_timestamps, dtype=np.float64)
        f.create_dataset('right_angles', data=right_angles, dtype=np.float32)
        f.create_dataset('right_timestamps', data=right_timestamps, dtype=np.float64)
        f.create_dataset('sync_timestamps', data=sync_timestamps, dtype=np.float64)
    
    write_time = time.time() - write_start
    total_time = time.time() - start_time
    
    file_size = os.path.getsize(filepath) / (1024 * 1024)
    
    print(f"  å†™å…¥è€—æ—¶: {write_time:.2f}s")
    print(f"  æ€»è€—æ—¶: {total_time:.2f}s")
    print(f"  æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
    print(f"âœ… ä¿å­˜å®Œæˆ: {filepath}")
    
    return filepath



def visualize_dual_hand(collector: DualHandCollector):
    """å¯è§†åŒ–åŒæ‰‹æ•°æ®"""
    print("\nåŒæ‰‹å¯è§†åŒ–ï¼ˆæŒ‰ 'q' é€€å‡ºï¼‰...")
    
    window_name = "Dual Hand - Press 'q' to quit"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    
    left_angle_history = []
    right_angle_history = []
    max_history = 100
    
    # å†…å­˜ç›‘æŽ§
    process = None
    initial_memory_mb = 0
    if HAS_PSUTIL:
        try:
            import psutil
            process = psutil.Process(os.getpid())
            initial_memory_mb = process.memory_info().rss / (1024 * 1024)
        except:
            pass
    
    try:
        while True:
            left_frame = collector.left.get_current_frame() if collector.left else None
            right_frame = collector.right.get_current_frame() if collector.right else None
            
            if left_frame is None and right_frame is None:
                time.sleep(0.01)
                continue
            
            # èŽ·å–å†…å­˜ä¿¡æ¯
            mem_text = ""
            if process:
                try:
                    mem_mb = process.memory_info().rss / (1024 * 1024)
                    mem_delta = mem_mb - initial_memory_mb
                    mem_text = f"Memory: {mem_mb:.0f}MB (+{mem_delta:.0f}MB)"
                except:
                    pass
            
            displays = []
            
            # å¤„ç†å·¦æ‰‹
            if left_frame:
                stereo_img = left_frame.stereo.copy()
                mono_img = left_frame.mono.copy()
                angle = left_frame.angle
                
                left_angle_history.append(angle)
                if len(left_angle_history) > max_history:
                    left_angle_history.pop(0)
                
                # åˆ†å‰²åŒç›®
                stereo_h, stereo_w = stereo_img.shape[:2]
                if stereo_w > stereo_h:
                    left_stereo = stereo_img[:, :stereo_w//2]
                    right_stereo = stereo_img[:, stereo_w//2:]
                else:
                    left_stereo = stereo_img[:stereo_h//2, :]
                    right_stereo = stereo_img[stereo_h//2:, :]
                
                # ä¿æŒåŽŸå§‹å°ºå¯¸ï¼Œä¸è¿›è¡Œresize
                mono_display = mono_img.copy()
                left_display = left_stereo.copy()
                right_display = right_stereo.copy()
                
                # è§’åº¦æ˜¾ç¤ºï¼ˆé«˜åº¦ä¸Žmono_displayåŒ¹é…ï¼‰
                angle_img = np.zeros((mono_display.shape[0], 300, 3), dtype=np.uint8)
                angle_img_h = angle_img.shape[0]
                angle_img_w = angle_img.shape[1]
                cv2.putText(angle_img, f"L: {angle:.2f}", (10, 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºå†…å­˜ï¼ˆä»…åœ¨å·¦ä¾§æ˜¾ç¤ºä¸€æ¬¡ï¼‰
                if mem_text:
                    cv2.putText(angle_img, mem_text, (10, 55), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
                
                if len(left_angle_history) > 1:
                    points = []
                    for i, a in enumerate(left_angle_history):
                        x = int((i / max(len(left_angle_history) - 1, 1)) * (angle_img_w - 20) + 10)
                        y = int(angle_img_h - 20 - (a + 180) / 360 * (angle_img_h - 40))
                        points.append((x, y))
                    for i in range(len(points) - 1):
                        cv2.line(angle_img, points[i], points[i+1], (0, 255, 255), 2)
                
                left_row = np.hstack([left_display, right_display])
                left_bottom = np.hstack([mono_display, angle_img])
                if left_row.shape[1] != left_bottom.shape[1]:
                    target_w = max(left_row.shape[1], left_bottom.shape[1])
                    if left_row.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((left_row.shape[0], target_w - left_row.shape[1], 3), dtype=np.uint8)
                        left_row = np.hstack([left_row, padding])
                    if left_bottom.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((left_bottom.shape[0], target_w - left_bottom.shape[1], 3), dtype=np.uint8)
                        left_bottom = np.hstack([left_bottom, padding])
                
                left_display_full = np.vstack([left_row, left_bottom])
                displays.append(left_display_full)
            
            # å¤„ç†å³æ‰‹
            if right_frame:
                stereo_img = right_frame.stereo.copy()
                mono_img = right_frame.mono.copy()
                angle = right_frame.angle
                
                right_angle_history.append(angle)
                if len(right_angle_history) > max_history:
                    right_angle_history.pop(0)
                
                # åˆ†å‰²åŒç›®
                stereo_h, stereo_w = stereo_img.shape[:2]
                if stereo_w > stereo_h:
                    left_stereo = stereo_img[:, :stereo_w//2]
                    right_stereo = stereo_img[:, stereo_w//2:]
                else:
                    left_stereo = stereo_img[:stereo_h//2, :]
                    right_stereo = stereo_img[stereo_h//2:, :]
                
                # ä¿æŒåŽŸå§‹å°ºå¯¸ï¼Œä¸è¿›è¡Œresize
                mono_display = mono_img.copy()
                left_display = left_stereo.copy()
                right_display = right_stereo.copy()
                
                # è§’åº¦æ˜¾ç¤ºï¼ˆé«˜åº¦ä¸Žmono_displayåŒ¹é…ï¼‰
                angle_img = np.zeros((mono_display.shape[0], 300, 3), dtype=np.uint8)
                angle_img_h = angle_img.shape[0]
                angle_img_w = angle_img.shape[1]
                cv2.putText(angle_img, f"R: {angle:.2f}", (10, 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                if len(right_angle_history) > 1:
                    points = []
                    for i, a in enumerate(right_angle_history):
                        x = int((i / max(len(right_angle_history) - 1, 1)) * (angle_img_w - 20) + 10)
                        y = int(angle_img_h - 20 - (a + 180) / 360 * (angle_img_h - 40))
                        points.append((x, y))
                    for i in range(len(points) - 1):
                        cv2.line(angle_img, points[i], points[i+1], (0, 255, 255), 2)
                
                right_row = np.hstack([left_display, right_display])
                right_bottom = np.hstack([mono_display, angle_img])
                if right_row.shape[1] != right_bottom.shape[1]:
                    target_w = max(right_row.shape[1], right_bottom.shape[1])
                    if right_row.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((right_row.shape[0], target_w - right_row.shape[1], 3), dtype=np.uint8)
                        right_row = np.hstack([right_row, padding])
                    if right_bottom.shape[1] < target_w:
                        # åœ¨å³ä¾§å¡«å……é»‘è‰²
                        padding = np.zeros((right_bottom.shape[0], target_w - right_bottom.shape[1], 3), dtype=np.uint8)
                        right_bottom = np.hstack([right_bottom, padding])
                
                right_display_full = np.vstack([right_row, right_bottom])
                displays.append(right_display_full)
            
            if displays:
                # ç»„åˆæ˜¾ç¤º
                if len(displays) == 2:
                    # åŒæ‰‹ï¼šä¸Šä¸‹æŽ’åˆ—
                    final_display = np.vstack(displays)
                else:
                    final_display = displays[0]
                
                # æ·»åŠ æ ‡é¢˜
                title_height = 30
                title_img = np.zeros((title_height, final_display.shape[1], 3), dtype=np.uint8)
                title_text = "Dual Hand Visualization - Press 'q' to quit"
                cv2.putText(title_img, title_text, (10, 20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
                final_display = np.vstack([title_img, final_display])
                
                cv2.imshow(window_name, final_display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            
            time.sleep(0.01)
    
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyWindow(window_name)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="åŒæ‰‹æ•°æ®æ”¶é›†å™¨")
    parser.add_argument("--config", "-c", type=str, default="config.yaml",
                       help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--mode", "-m", type=str, choices=['left', 'right', 'both'],
                       default='both', help="æµ‹è¯•æ¨¡å¼: left(å·¦æ‰‹), right(å³æ‰‹), both(åŒæ‰‹)")
    parser.add_argument("--visualize", "-v", action="store_true",
                       help="å¯ç”¨å¯è§†åŒ–æ¨¡å¼")
    parser.add_argument("--record", "-r", action="store_true",
                       help="å½•åˆ¶æ¨¡å¼ï¼ˆä¸Žå¯è§†åŒ–æ¨¡å¼äº’æ–¥ï¼‰")
    args = parser.parse_args()
    
    config_path = args.config
    if not os.path.isabs(config_path):
        config_path = os.path.join(os.path.dirname(__file__), config_path)
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)
    
    # å¦‚æžœæ²¡æœ‰æŒ‡å®šæ¨¡å¼ï¼Œé»˜è®¤ä½¿ç”¨å¯è§†åŒ–
    if not args.visualize and not args.record:
        args.visualize = True
    
    try:
        if args.mode == 'both':
            # åŒæ‰‹æ¨¡å¼
            collector = DualHandCollector(config_path)
            collector.start()
            if not collector.wait_ready():
                print("âŒ åˆå§‹åŒ–å¤±è´¥")
                sys.exit(1)
            
            if args.visualize:
                visualize_dual_hand(collector)
            elif args.record:
                print("\næŒ‰å›žè½¦é”®å¼€å§‹å½•åˆ¶...")
                input()
                collector.start_recording()
                print("å½•åˆ¶ä¸­... æŒ‰å›žè½¦é”®åœæ­¢å½•åˆ¶")
                input()
                data = collector.stop_recording()
                if data:
                    save_cfg = collector.config.get('save', {})
                    output_dir = save_cfg.get('output_dir', './data')
                    jpeg_quality = save_cfg.get('jpeg_quality', 85)
                    save_dual_hand_data(data, output_dir, jpeg_quality)
            collector.stop()
        
        else:
            # å•æ‰‹æ¨¡å¼
            config = yaml.safe_load(open(config_path, 'r'))
            hand_name = args.mode.upper()
            hand_config = config.get(f'{args.mode}_hand', {})
            
            if not hand_config:
                print(f"âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° {args.mode}_hand é…ç½®")
                sys.exit(1)
            
            collector = HandCollector(hand_config, hand_name)
            collector.start()
            if not collector.wait_ready():
                print("âŒ åˆå§‹åŒ–å¤±è´¥")
                sys.exit(1)
            
            # é¢„çƒ­å’Œæ ¡å‡†
            sync_cfg = config.get('sync', {})
            warmup_time = sync_cfg.get('warmup_time', 1.0)
            calib_time = sync_cfg.get('calib_time', 0.5)
            collector.warmup_and_calibrate(warmup_time, calib_time)
            
            if args.visualize:
                visualize_hand(collector, hand_name)
            elif args.record:
                print("\næŒ‰å›žè½¦é”®å¼€å§‹å½•åˆ¶...")
                input()
                collector.start_recording()
                print("å½•åˆ¶ä¸­... æŒ‰å›žè½¦é”®åœæ­¢å½•åˆ¶")
                input()
                data = collector.stop_recording()
                if data:
                    print(f"\nå½•åˆ¶å®Œæˆ: {len(data)} å¸§")
                    # å•æ‰‹æ•°æ®å¯ä»¥ä¿å­˜ä¸ºå•ç‹¬çš„HDF5æ–‡ä»¶
                    save_cfg = config.get('save', {})
                    output_dir = save_cfg.get('output_dir', './data')
                    jpeg_quality = save_cfg.get('jpeg_quality', 85)
                    # è¿™é‡Œå¯ä»¥æ·»åŠ å•æ‰‹ä¿å­˜å‡½æ•°ï¼Œæš‚æ—¶åªæ‰“å°
                    print(f"æ•°æ®å·²æ”¶é›†ï¼Œå¯æ‰©å±•ä¿å­˜åŠŸèƒ½")
            
            collector.stop()
        
    except KeyboardInterrupt:
        print("\nä¸­æ–­")
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"\né”™è¯¯: {e}")

