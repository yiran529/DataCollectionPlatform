#!/usr/bin/env python3
"""
åŒæ‘„åƒå¤´åŒæ­¥æ•è·

åŒæ—¶ä»ä¸¤ä¸ªæ‘„åƒå¤´æ•è·å›¾åƒï¼š
- æ‘„åƒå¤´1: DECXIN ç«‹ä½“ç›¸æœº (3840x1080 @ 60fps)
- æ‘„åƒå¤´2: DECXIN å•ç›®ç›¸æœº (1280x1024 @ 60fps)

æ”¯æŒå›ºå®šåç§»è¡¥å¿ï¼Œå°†å®ƒä»¬æ‹¼æ¥å¹¶ä¿å­˜ä¸ºè§†é¢‘ã€‚
"""

import cv2
import numpy as np
import time
import os
import threading
import argparse
from queue import Queue
from datetime import datetime
from dataclasses import dataclass
from typing import Optional, Tuple, List

# é»˜è®¤åç§»é‡ (ms): ç«‹ä½“ç›¸æœºæ¯”å•ç›®ç›¸æœºæ…¢çš„æ—¶é—´
# é€šè¿‡ analyze_timestamps.py åˆ†æå¾—å‡º
DEFAULT_STEREO_MONO_OFFSET_MS = 35.0


@dataclass
class FrameData:
    """å¸§æ•°æ®"""
    frame: np.ndarray
    timestamp: float
    frame_idx: int
    camera_id: int


class CameraReader:
    """å•ä¸ªæ‘„åƒå¤´è¯»å–å™¨ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
    
    def __init__(self, device_id: int, width: int, height: int, fps: int, name: str):
        self.device_id = device_id
        self.width = width
        self.height = height
        self.fps = fps
        self.name = name
        
        self.cap: Optional[cv2.VideoCapture] = None
        self.frame_queue: Queue = Queue(maxsize=30)
        self.running = False
        self.thread: Optional[threading.Thread] = None
        self.frame_count = 0
        self.start_time = 0.0
        
    def open(self) -> bool:
        """æ‰“å¼€æ‘„åƒå¤´"""
        # ä½¿ç”¨é»˜è®¤åç«¯ï¼ˆä¸è¦ç”¨ V4L2ï¼Œä¼šé™åˆ¶å¸§ç‡ï¼‰
        self.cap = cv2.VideoCapture(self.device_id)
        if not self.cap.isOpened():
            print(f"[{self.name}] æ— æ³•æ‰“å¼€è®¾å¤‡ {self.device_id}")
            return False
        
        # å¿…é¡»å…ˆè®¾ç½® MJPG æ ¼å¼æ‰èƒ½è¾¾åˆ°é«˜å¸§ç‡
        self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)
        self.cap.set(cv2.CAP_PROP_FPS, self.fps)
        
        actual_w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        actual_fps = self.cap.get(cv2.CAP_PROP_FPS)
        
        print(f"[{self.name}] è®¾å¤‡ {self.device_id}: {actual_w}x{actual_h} @ {actual_fps}fps")
        return True
    
    def start(self):
        """å¯åŠ¨è¯»å–çº¿ç¨‹"""
        self.running = True
        self.frame_count = 0
        self.start_time = time.time()
        self.thread = threading.Thread(target=self._read_loop, daemon=True)
        self.thread.start()
    
    def stop(self):
        """åœæ­¢è¯»å–"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=2.0)
        if self.cap:
            self.cap.release()
    
    def _read_loop(self):
        """è¯»å–å¾ªç¯"""
        # é¢„çƒ­
        for _ in range(5):
            self.cap.read()
        
        while self.running:
            ret, frame = self.cap.read()
            timestamp = time.time()
            
            if ret:
                self.frame_count += 1
                
                # éé˜»å¡æ”¾å…¥é˜Ÿåˆ—ï¼Œå¦‚æœæ»¡äº†å°±ä¸¢å¼ƒæœ€æ—§çš„
                if self.frame_queue.full():
                    try:
                        self.frame_queue.get_nowait()
                    except:
                        pass
                
                self.frame_queue.put(FrameData(
                    frame=frame,
                    timestamp=timestamp,
                    frame_idx=self.frame_count,
                    camera_id=self.device_id
                ))
    
    def get_frame(self, timeout: float = 0.1) -> Optional[FrameData]:
        """è·å–æœ€æ–°å¸§"""
        try:
            return self.frame_queue.get(timeout=timeout)
        except:
            return None
    
    def get_latest_frame(self) -> Optional[FrameData]:
        """è·å–é˜Ÿåˆ—ä¸­æœ€æ–°çš„å¸§ï¼ˆæ¸…ç©ºé˜Ÿåˆ—ï¼Œè¿”å›æœ€åä¸€ä¸ªï¼‰"""
        latest = None
        while True:
            try:
                latest = self.frame_queue.get_nowait()
            except:
                break
        return latest
    
    def get_fps(self) -> float:
        """è·å–å®é™…å¸§ç‡"""
        elapsed = time.time() - self.start_time
        return self.frame_count / elapsed if elapsed > 0 else 0


def align_frames(stereo_data: FrameData, mono_data: FrameData, 
                 output_height: int = 720) -> Tuple[np.ndarray, float]:
    """
    å¯¹é½å¹¶æ‹¼æ¥åŒç›®å’Œå•ç›®å›¾åƒ
    
    å¸ƒå±€:
    +------------------+--------+
    |    å·¦å›¾ (L)      |        |
    +------------------+  å•ç›®  |
    |    å³å›¾ (R)      |        |
    +------------------+--------+
    
    Returns:
        æ‹¼æ¥åçš„å›¾åƒ, æ—¶é—´å·®(ms)
    """
    stereo_frame = stereo_data.frame
    mono_frame = mono_data.frame
    
    # åˆ†å‰²ç«‹ä½“å›¾åƒ
    mid = stereo_frame.shape[1] // 2
    left_img = stereo_frame[:, :mid]
    right_img = stereo_frame[:, mid:]
    
    # è°ƒæ•´å°ºå¯¸
    # å·¦å³å›¾å„ 960x540ï¼Œå•ç›® 480x720
    left_resized = cv2.resize(left_img, (960, output_height // 2))
    right_resized = cv2.resize(right_img, (960, output_height // 2))
    
    # å•ç›®å›¾åƒè°ƒæ•´ä¸ºå³ä¾§é«˜åº¦
    mono_h = output_height
    mono_w = int(mono_frame.shape[1] * mono_h / mono_frame.shape[0])
    mono_resized = cv2.resize(mono_frame, (mono_w, mono_h))
    
    # å‚ç›´æ‹¼æ¥å·¦å³å›¾
    stereo_combined = np.vstack([left_resized, right_resized])
    
    # æ°´å¹³æ‹¼æ¥
    canvas_w = stereo_combined.shape[1] + mono_resized.shape[1]
    canvas = np.zeros((output_height, canvas_w, 3), dtype=np.uint8)
    
    canvas[:, :stereo_combined.shape[1]] = stereo_combined
    canvas[:, stereo_combined.shape[1]:] = mono_resized
    
    # è®¡ç®—æ—¶é—´å·®
    time_diff_ms = (stereo_data.timestamp - mono_data.timestamp) * 1000
    
    return canvas, time_diff_ms


def main():
    parser = argparse.ArgumentParser(description="åŒæ‘„åƒå¤´åŒæ­¥æ•è·")
    parser.add_argument("--stereo-device", type=int, default=6, help="ç«‹ä½“ç›¸æœºè®¾å¤‡ID")
    parser.add_argument("--stereo-width", type=int, default=3840, help="ç«‹ä½“ç›¸æœºå®½åº¦")
    parser.add_argument("--stereo-height", type=int, default=1080, help="ç«‹ä½“ç›¸æœºé«˜åº¦")
    parser.add_argument("--stereo-fps", type=int, default=60, help="ç«‹ä½“ç›¸æœºå¸§ç‡")
    
    parser.add_argument("--mono-device", type=int, default=4, help="å•ç›®ç›¸æœºè®¾å¤‡ID")
    parser.add_argument("--mono-width", type=int, default=1280, help="å•ç›®ç›¸æœºå®½åº¦")
    parser.add_argument("--mono-height", type=int, default=1024, help="å•ç›®ç›¸æœºé«˜åº¦")
    parser.add_argument("--mono-fps", type=int, default=60, help="å•ç›®ç›¸æœºå¸§ç‡")
    
    parser.add_argument("--duration", "-t", type=int, default=10, help="å½•åˆ¶æ—¶é•¿(ç§’)")
    parser.add_argument("--output", "-o", type=str, default="sync_test", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--preview", "-p", action="store_true", help="æ˜¾ç¤ºå®æ—¶é¢„è§ˆ")
    parser.add_argument("--offset", type=float, default=DEFAULT_STEREO_MONO_OFFSET_MS,
                        help=f"ç«‹ä½“ç›¸æœºæ—¶é—´åç§»é‡(ms)ï¼Œé»˜è®¤{DEFAULT_STEREO_MONO_OFFSET_MS}")
    parser.add_argument("--no-offset", action="store_true", help="ä¸åº”ç”¨åç§»è¡¥å¿ï¼ˆç”¨äºæµ‹é‡åŸå§‹åç§»ï¼‰")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(args.output, f"capture_{timestamp}")
    os.makedirs(output_dir, exist_ok=True)
    
    # åç§»è®¾ç½®
    offset_ms = 0.0 if args.no_offset else args.offset
    
    print("=" * 60)
    print("åŒæ‘„åƒå¤´åŒæ­¥æ•è·")
    print("=" * 60)
    print(f"ç«‹ä½“ç›¸æœº: device={args.stereo_device}, {args.stereo_width}x{args.stereo_height}@{args.stereo_fps}fps")
    print(f"å•ç›®ç›¸æœº: device={args.mono_device}, {args.mono_width}x{args.mono_height}@{args.mono_fps}fps")
    print(f"æ—¶é—´åç§»è¡¥å¿: {offset_ms:.1f} ms" + (" (å·²ç¦ç”¨)" if args.no_offset else ""))
    print(f"å½•åˆ¶æ—¶é•¿: {args.duration} ç§’")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ‘„åƒå¤´
    stereo_cam = CameraReader(args.stereo_device, args.stereo_width, args.stereo_height, 
                               args.stereo_fps, "STEREO")
    mono_cam = CameraReader(args.mono_device, args.mono_width, args.mono_height,
                            args.mono_fps, "MONO")
    
    if not stereo_cam.open():
        return
    if not mono_cam.open():
        stereo_cam.stop()
        return
    
    # è§†é¢‘è¾“å‡ºè®¾ç½®
    output_height = 720
    output_width = 960 + int(args.mono_width * output_height / args.mono_height)
    output_fps = min(args.stereo_fps, args.mono_fps)
    
    video_path = os.path.join(output_dir, "sync_video.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(video_path, fourcc, output_fps, (output_width, output_height))
    
    # æ—¶é—´æˆ³æ–‡ä»¶
    timestamp_path = os.path.join(output_dir, "timestamps.txt")
    timestamp_file = open(timestamp_path, 'w')
    timestamp_file.write(f"# offset_ms={offset_ms:.1f}\n")
    timestamp_file.write("# frame_idx, stereo_timestamp, mono_timestamp, raw_diff_ms, corrected_diff_ms\n")
    
    print(f"\nè§†é¢‘è¾“å‡º: {output_width}x{output_height} @ {output_fps}fps")
    print(f"æŒ‰ Ctrl+C æˆ– 'q' åœæ­¢\n")
    
    # å¯åŠ¨æ‘„åƒå¤´
    stereo_cam.start()
    mono_cam.start()
    
    # ç­‰å¾…æ‘„åƒå¤´ç¨³å®š
    time.sleep(0.5)
    
    frame_count = 0
    time_diffs = []
    start_time = time.time()
    
    try:
        while time.time() - start_time < args.duration:
            # è·å–å¸§ï¼ˆæ¯ä¸ªé˜Ÿåˆ—è·å–ä¸€å¸§ï¼Œä¿æŒåŒæ­¥ï¼‰
            stereo_data = stereo_cam.get_frame(timeout=0.05)
            mono_data = mono_cam.get_frame(timeout=0.05)
            
            if stereo_data is None or mono_data is None:
                continue
            
            # å¯¹é½å¹¶æ‹¼æ¥
            combined, raw_diff_ms = align_frames(stereo_data, mono_data, output_height)
            
            # åº”ç”¨åç§»è¡¥å¿åçš„æ—¶é—´å·®
            corrected_diff_ms = raw_diff_ms - offset_ms
            time_diff_ms = corrected_diff_ms  # ç”¨äºæ˜¾ç¤ºå’Œç»Ÿè®¡
            time_diffs.append(time_diff_ms)
            
            # æ·»åŠ ä¿¡æ¯å åŠ 
            info_text = f"Frame: {frame_count} | Stereo FPS: {stereo_cam.get_fps():.1f} | Mono FPS: {mono_cam.get_fps():.1f}"
            cv2.putText(combined, info_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            diff_color = (0, 255, 0) if abs(time_diff_ms) < 20 else (0, 165, 255) if abs(time_diff_ms) < 50 else (0, 0, 255)
            diff_text = f"Time Diff: {time_diff_ms:+.2f} ms"
            cv2.putText(combined, diff_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, diff_color, 2)
            
            # æ ‡ç­¾
            cv2.putText(combined, "LEFT", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            cv2.putText(combined, "RIGHT", (10, output_height // 2 + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            cv2.putText(combined, "MONO", (970, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            
            # åˆ†å‰²çº¿
            cv2.line(combined, (960, 0), (960, output_height), (100, 100, 100), 2)
            cv2.line(combined, (0, output_height // 2), (960, output_height // 2), (100, 100, 100), 1)
            
            # å†™å…¥è§†é¢‘
            video_writer.write(combined)
            
            # è®°å½•æ—¶é—´æˆ³
            timestamp_file.write(f"{frame_count}, {stereo_data.timestamp:.6f}, {mono_data.timestamp:.6f}, {raw_diff_ms:.3f}, {corrected_diff_ms:.3f}\n")
            
            frame_count += 1
            
            # é¢„è§ˆ
            if args.preview:
                cv2.imshow("Dual Camera Sync", combined)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("\nç”¨æˆ·ä¸­æ–­")
                    break
            
            # è¿›åº¦
            if frame_count % output_fps == 0:
                elapsed = time.time() - start_time
                avg_diff = np.mean(time_diffs[-output_fps:])
                print(f"  å·²å½•åˆ¶ {frame_count} å¸§ ({elapsed:.1f}s), å¹³å‡æ—¶é—´å·®: {avg_diff:+.2f} ms")
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
    
    finally:
        # åœæ­¢
        stereo_cam.stop()
        mono_cam.stop()
        video_writer.release()
        timestamp_file.close()
        
        if args.preview:
            cv2.destroyAllWindows()
    
    # ç»Ÿè®¡
    total_time = time.time() - start_time
    
    print("\n" + "=" * 60)
    print("å½•åˆ¶å®Œæˆ!")
    print("=" * 60)
    print(f"æ€»å¸§æ•°: {frame_count}")
    print(f"å½•åˆ¶æ—¶é•¿: {total_time:.2f} ç§’")
    print(f"å®é™…å¸§ç‡: {frame_count / total_time:.2f} fps")
    
    if time_diffs:
        print(f"\næ—¶é—´å·®ç»Ÿè®¡ (è¡¥å¿å):")
        print(f"  åº”ç”¨åç§»: {offset_ms:.1f} ms")
        print(f"  å¹³å‡è¯¯å·®: {np.mean(time_diffs):+.2f} ms")
        print(f"  æ ‡å‡†å·®: {np.std(time_diffs):.2f} ms")
        print(f"  èŒƒå›´: {np.min(time_diffs):+.2f} ~ {np.max(time_diffs):+.2f} ms")
        
        # åˆ¤æ–­åŒæ­¥è´¨é‡
        avg_diff = abs(np.mean(time_diffs))
        std_diff = np.std(time_diffs)
        
        if avg_diff < 20 and std_diff < 30:
            print(f"\nâœ… åŒæ­¥è´¨é‡: è‰¯å¥½ (å¹³å‡è¯¯å·®<20ms)")
        elif avg_diff < 50 and std_diff < 50:
            print(f"\nğŸ”¶ åŒæ­¥è´¨é‡: ä¸€èˆ¬ (å¹³å‡è¯¯å·®<50ms)")
        else:
            print(f"\nâŒ åŒæ­¥è´¨é‡: è¾ƒå·® (å»ºè®®é‡æ–°æ ¡å‡†åç§»æˆ–ä½¿ç”¨ç¡¬ä»¶åŒæ­¥)")
    
    print(f"\nè¾“å‡ºæ–‡ä»¶:")
    print(f"  è§†é¢‘: {video_path}")
    print(f"  æ—¶é—´æˆ³: {timestamp_path}")
    print("=" * 60)


if __name__ == "__main__":
    main()

