#!/usr/bin/env python3
"""
åŒ GoPro ç›¸æœºåŒæ­¥æ•è·

åŒæ—¶ä»ä¸¤ä¸ª GoPro æ•è· 1080p @ 60fps å›¾åƒï¼Œ
æ”¯æŒåç§»æµ‹é‡å’Œè¡¥å¿ã€‚
"""

import cv2
import numpy as np
import time
import os
import threading
import argparse
from queue import Queue
from datetime import datetime
from dataclasses import dataclass
from typing import Optional, Tuple, List

# é»˜è®¤åç§»é‡ (ms): cam1 æ¯” cam2 æ…¢çš„æ—¶é—´
DEFAULT_OFFSET_MS = 0.0


@dataclass
class FrameData:
    """å¸§æ•°æ®"""
    frame: np.ndarray
    timestamp: float
    frame_idx: int
    camera_id: int


class CameraReader:
    """å•ä¸ªæ‘„åƒå¤´è¯»å–å™¨ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
    
    def __init__(self, device_id: int, width: int, height: int, fps: int, name: str):
        self.device_id = device_id
        self.width = width
        self.height = height
        self.fps = fps
        self.name = name
        
        self.cap: Optional[cv2.VideoCapture] = None
        self.frame_queue: Queue = Queue(maxsize=30)
        self.running = False
        self.thread: Optional[threading.Thread] = None
        self.frame_count = 0
        self.start_time = 0.0
        
    def open(self) -> bool:
        """æ‰“å¼€æ‘„åƒå¤´"""
        # ä½¿ç”¨é»˜è®¤åç«¯ï¼ˆä¸è¦ç”¨ V4L2ï¼Œä¼šé™åˆ¶å¸§ç‡ï¼‰
        self.cap = cv2.VideoCapture(self.device_id)
        if not self.cap.isOpened():
            print(f"[{self.name}] æ— æ³•æ‰“å¼€è®¾å¤‡ {self.device_id}")
            return False
        
        # å¿…é¡»å…ˆè®¾ç½® MJPG æ ¼å¼æ‰èƒ½è¾¾åˆ°é«˜å¸§ç‡
        self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)
        self.cap.set(cv2.CAP_PROP_FPS, self.fps)
        
        actual_w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        actual_fps = self.cap.get(cv2.CAP_PROP_FPS)
        
        print(f"[{self.name}] è®¾å¤‡ {self.device_id}: {actual_w}x{actual_h} @ {actual_fps}fps")
        return True
    
    def start(self):
        """å¯åŠ¨è¯»å–çº¿ç¨‹"""
        self.running = True
        self.frame_count = 0
        self.start_time = time.time()
        self.thread = threading.Thread(target=self._read_loop, daemon=True)
        self.thread.start()
    
    def stop(self):
        """åœæ­¢è¯»å–"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=2.0)
        if self.cap:
            self.cap.release()
    
    def _read_loop(self):
        """è¯»å–å¾ªç¯"""
        # é¢„çƒ­
        for _ in range(5):
            self.cap.read()
        
        while self.running:
            ret, frame = self.cap.read()
            timestamp = time.time()
            
            if ret:
                self.frame_count += 1
                
                # éé˜»å¡æ”¾å…¥é˜Ÿåˆ—ï¼Œå¦‚æœæ»¡äº†å°±ä¸¢å¼ƒæœ€æ—§çš„
                if self.frame_queue.full():
                    try:
                        self.frame_queue.get_nowait()
                    except:
                        pass
                
                self.frame_queue.put(FrameData(
                    frame=frame,
                    timestamp=timestamp,
                    frame_idx=self.frame_count,
                    camera_id=self.device_id
                ))
    
    def get_frame(self, timeout: float = 0.1) -> Optional[FrameData]:
        """è·å–æœ€æ–°å¸§"""
        try:
            return self.frame_queue.get(timeout=timeout)
        except:
            return None
    
    def get_latest_frame(self) -> Optional[FrameData]:
        """è·å–é˜Ÿåˆ—ä¸­æœ€æ–°çš„å¸§ï¼ˆæ¸…ç©ºé˜Ÿåˆ—ï¼Œè¿”å›æœ€åä¸€ä¸ªï¼‰"""
        latest = None
        while True:
            try:
                latest = self.frame_queue.get_nowait()
            except:
                break
        return latest
    
    def get_fps(self) -> float:
        """è·å–å®é™…å¸§ç‡"""
        elapsed = time.time() - self.start_time
        return self.frame_count / elapsed if elapsed > 0 else 0


def align_frames(cam1_data: FrameData, cam2_data: FrameData, 
                 output_height: int = 540, output_width: int = 1920) -> Tuple[np.ndarray, float]:
    """
    æ°´å¹³æ‹¼æ¥ä¸¤ä¸ªç›¸æœºå›¾åƒåˆ°å›ºå®šå°ºå¯¸
    
    Returns:
        æ‹¼æ¥åçš„å›¾åƒ(å›ºå®šå°ºå¯¸), æ—¶é—´å·®(ms)
    """
    half_w = output_width // 2
    
    # è°ƒæ•´ä¸¤ä¸ªå›¾åƒåˆ°ç›¸åŒå°ºå¯¸
    img1 = cv2.resize(cam1_data.frame, (half_w, output_height))
    img2 = cv2.resize(cam2_data.frame, (half_w, output_height))
    
    # æ°´å¹³æ‹¼æ¥
    combined = np.hstack([img1, img2])
    
    # è®¡ç®—æ—¶é—´å·®
    time_diff_ms = (cam1_data.timestamp - cam2_data.timestamp) * 1000
    
    return combined, time_diff_ms


def main():
    parser = argparse.ArgumentParser(description="åŒ GoPro ç›¸æœºåŒæ­¥æ•è·")
    parser.add_argument("--cam1", type=int, default=0, help="GoPro 1 è®¾å¤‡ID")
    parser.add_argument("--cam2", type=int, default=2, help="GoPro 2 è®¾å¤‡ID")
    parser.add_argument("--width", type=int, default=1920, help="åˆ†è¾¨ç‡å®½åº¦")
    parser.add_argument("--height", type=int, default=1080, help="åˆ†è¾¨ç‡é«˜åº¦")
    parser.add_argument("--fps", type=int, default=60, help="å¸§ç‡")
    
    parser.add_argument("--duration", "-t", type=int, default=10, help="å½•åˆ¶æ—¶é•¿(ç§’)")
    parser.add_argument("--output", "-o", type=str, default="gopro_sync", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--preview", "-p", action="store_true", help="æ˜¾ç¤ºå®æ—¶é¢„è§ˆ")
    parser.add_argument("--offset", type=float, default=DEFAULT_OFFSET_MS,
                        help=f"CAM1 æ—¶é—´åç§»é‡(ms)ï¼Œé»˜è®¤{DEFAULT_OFFSET_MS}")
    parser.add_argument("--measure", "-m", action="store_true", help="æµ‹é‡åç§»æ¨¡å¼ï¼ˆä¸ä¿å­˜è§†é¢‘ï¼Œåªç»Ÿè®¡ï¼‰")
    
    args = parser.parse_args()
    
    # æµ‹é‡æ¨¡å¼è‡ªåŠ¨å¯ç”¨é¢„è§ˆ
    if args.measure:
        args.preview = True
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(args.output, f"capture_{timestamp_str}")
    if not args.measure:
        os.makedirs(output_dir, exist_ok=True)
    
    print("=" * 60)
    print("åŒ GoPro åŒæ­¥æ•è·" + (" [æµ‹é‡æ¨¡å¼]" if args.measure else ""))
    print("=" * 60)
    print(f"CAM1: device={args.cam1}, {args.width}x{args.height}@{args.fps}fps")
    print(f"CAM2: device={args.cam2}, {args.width}x{args.height}@{args.fps}fps")
    print(f"æ—¶é—´åç§»è¡¥å¿: {args.offset:.1f} ms")
    print(f"å½•åˆ¶æ—¶é•¿: {args.duration} ç§’")
    if not args.measure:
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ‘„åƒå¤´
    cam1 = CameraReader(args.cam1, args.width, args.height, args.fps, "CAM1")
    cam2 = CameraReader(args.cam2, args.width, args.height, args.fps, "CAM2")
    
    if not cam1.open():
        return
    if not cam2.open():
        cam1.stop()
        return
    
    # è§†é¢‘è¾“å‡ºè®¾ç½®ï¼ˆå›ºå®šå°ºå¯¸ï¼Œé¿å…ç¼–ç é—®é¢˜ï¼‰
    output_height = 540
    output_width = 1920  # å›ºå®šå®½åº¦ï¼Œæ¯ä¸ªç›¸æœº 960
    output_fps = args.fps
    
    video_writer = None
    timestamp_file = None
    video_path = None
    timestamp_path = None
    
    if not args.measure:
        video_path = os.path.join(output_dir, "sync_video.mp4")
        # ä½¿ç”¨ XVID ç¼–ç å™¨ï¼Œæ›´å…¼å®¹
        fourcc = cv2.VideoWriter_fourcc(*'XVID')
        video_writer = cv2.VideoWriter(video_path.replace('.mp4', '.avi'), fourcc, output_fps, (output_width, output_height))
        if not video_writer.isOpened():
            # å¤‡é€‰ï¼šä½¿ç”¨ mp4v
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            video_writer = cv2.VideoWriter(video_path, fourcc, output_fps, (output_width, output_height))
        
        timestamp_path = os.path.join(output_dir, "timestamps.txt")
        timestamp_file = open(timestamp_path, 'w')
        timestamp_file.write(f"# offset_ms={args.offset:.1f}\n")
        timestamp_file.write("# frame_idx, cam1_timestamp, cam2_timestamp, raw_diff_ms, corrected_diff_ms\n")
    
    print(f"\né¢„è§ˆ: {output_width}x{output_height} @ {output_fps}fps")
    print(f"æŒ‰ 'q' åœæ­¢\n")
    
    # å¯åŠ¨æ‘„åƒå¤´
    cam1.start()
    cam2.start()
    
    # ç­‰å¾…æ‘„åƒå¤´ç¨³å®š
    print("é¢„çƒ­ä¸­...")
    time.sleep(2.0)
    
    frame_count = 0
    time_diffs = []
    raw_diffs = []
    start_time = time.time()
    
    try:
        while time.time() - start_time < args.duration:
            # è·å–å¸§
            cam1_data = cam1.get_frame(timeout=0.05)
            cam2_data = cam2.get_frame(timeout=0.05)
            
            if cam1_data is None or cam2_data is None:
                continue
            
            # å¯¹é½å¹¶æ‹¼æ¥ï¼ˆå›ºå®šå°ºå¯¸ï¼‰
            combined, raw_diff_ms = align_frames(cam1_data, cam2_data, output_height, output_width)
            raw_diffs.append(raw_diff_ms)
            
            # åº”ç”¨åç§»è¡¥å¿åçš„æ—¶é—´å·®
            corrected_diff_ms = raw_diff_ms - args.offset
            time_diffs.append(corrected_diff_ms)
            
            # æ·»åŠ ä¿¡æ¯å åŠ 
            info_text = f"Frame: {frame_count} | CAM1: {cam1.get_fps():.1f}fps | CAM2: {cam2.get_fps():.1f}fps"
            cv2.putText(combined, info_text, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            diff_color = (0, 255, 0) if abs(corrected_diff_ms) < 10 else (0, 165, 255) if abs(corrected_diff_ms) < 30 else (0, 0, 255)
            diff_text = f"Diff: {corrected_diff_ms:+.1f}ms (raw: {raw_diff_ms:+.1f}ms)"
            cv2.putText(combined, diff_text, (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, diff_color, 2)
            
            # æ ‡ç­¾
            cv2.putText(combined, "CAM1", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            cv2.putText(combined, "CAM2", (output_width // 2 + 10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            # åˆ†å‰²çº¿
            cv2.line(combined, (output_width // 2, 0), (output_width // 2, output_height), (100, 100, 100), 2)
            
            # å†™å…¥è§†é¢‘
            if video_writer:
                video_writer.write(combined)
            
            # è®°å½•æ—¶é—´æˆ³
            if timestamp_file:
                timestamp_file.write(f"{frame_count}, {cam1_data.timestamp:.6f}, {cam2_data.timestamp:.6f}, {raw_diff_ms:.3f}, {corrected_diff_ms:.3f}\n")
            
            frame_count += 1
            
            # é¢„è§ˆ
            if args.preview:
                cv2.imshow("GoPro Sync", combined)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("\nç”¨æˆ·ä¸­æ–­")
                    break
            
            # è¿›åº¦
            if frame_count % output_fps == 0:
                elapsed = time.time() - start_time
                avg_raw = np.mean(raw_diffs[-output_fps:])
                avg_corr = np.mean(time_diffs[-output_fps:])
                print(f"  [{elapsed:.0f}s] {frame_count}å¸§ | åŸå§‹åç§»: {avg_raw:+.1f}ms | æ ¡æ­£å: {avg_corr:+.1f}ms")
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
    
    finally:
        # åœæ­¢
        cam1.stop()
        cam2.stop()
        if video_writer:
            video_writer.release()
        if timestamp_file:
            timestamp_file.close()
        
        if args.preview:
            cv2.destroyAllWindows()
    
    # ç»Ÿè®¡
    total_time = time.time() - start_time
    
    print("\n" + "=" * 60)
    print("å®Œæˆ!" + (" [æµ‹é‡æ¨¡å¼]" if args.measure else ""))
    print("=" * 60)
    print(f"æ€»å¸§æ•°: {frame_count}")
    print(f"å½•åˆ¶æ—¶é•¿: {total_time:.2f} ç§’")
    print(f"å®é™…å¸§ç‡: {frame_count / total_time:.2f} fps")
    
    if raw_diffs:
        print(f"\nğŸ“Š åŸå§‹æ—¶é—´å·®ç»Ÿè®¡ (CAM1 - CAM2):")
        print(f"  å¹³å‡å€¼: {np.mean(raw_diffs):+.2f} ms")
        print(f"  ä¸­ä½æ•°: {np.median(raw_diffs):+.2f} ms")
        print(f"  æ ‡å‡†å·®: {np.std(raw_diffs):.2f} ms")
        print(f"  èŒƒå›´: {np.min(raw_diffs):+.2f} ~ {np.max(raw_diffs):+.2f} ms")
        
        if args.measure:
            # æµ‹é‡æ¨¡å¼ï¼šç»™å‡ºå»ºè®®åç§»é‡
            suggested_offset = np.median(raw_diffs)
            print(f"\nğŸ’¡ å»ºè®®åç§»é‡: {suggested_offset:.1f} ms")
            print(f"   ä½¿ç”¨æ–¹å¼: python {os.path.basename(__file__)} --offset {suggested_offset:.1f}")
        else:
            # æ­£å¸¸æ¨¡å¼ï¼šæ˜¾ç¤ºæ ¡æ­£åç»“æœ
            print(f"\nğŸ“Š æ ¡æ­£åæ—¶é—´å·®ç»Ÿè®¡:")
            print(f"  åº”ç”¨åç§»: {args.offset:.1f} ms")
            print(f"  å¹³å‡è¯¯å·®: {np.mean(time_diffs):+.2f} ms")
            print(f"  æ ‡å‡†å·®: {np.std(time_diffs):.2f} ms")
            
            avg_diff = abs(np.mean(time_diffs))
            if avg_diff < 10:
                print(f"\nâœ… åŒæ­¥è´¨é‡: ä¼˜ç§€ (å¹³å‡è¯¯å·®<10ms)")
            elif avg_diff < 20:
                print(f"\nâœ… åŒæ­¥è´¨é‡: è‰¯å¥½ (å¹³å‡è¯¯å·®<20ms)")
            elif avg_diff < 50:
                print(f"\nğŸ”¶ åŒæ­¥è´¨é‡: ä¸€èˆ¬ (å¹³å‡è¯¯å·®<50ms)")
            else:
                print(f"\nâŒ åŒæ­¥è´¨é‡: è¾ƒå·®")
    
    if not args.measure and video_path:
        actual_video = video_path.replace('.mp4', '.avi') if os.path.exists(video_path.replace('.mp4', '.avi')) else video_path
        print(f"\nè¾“å‡ºæ–‡ä»¶:")
        print(f"  è§†é¢‘: {actual_video}")
        print(f"  æ—¶é—´æˆ³: {timestamp_path}")
    print("=" * 60)


if __name__ == "__main__":
    main()

